{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"Colab Notebooks/prj_neuroread_analysis/neuroread/\"\n",
    "GOOGLE_DRIVE_PATH = os.path.join(\"/content\", \"drive\", \"MyDrive\", GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))\n",
    "\n",
    "# Add to sys so we can import .py files.\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "os.chdir(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "# Install unavailable packages\n",
    "import pip\n",
    "def import_or_install(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        pip.main(['install', package])\n",
    "\n",
    "import_or_install(\"mne\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    " print('Not connected to a GPU')\n",
    "else:\n",
    " print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "from tools.train import eval_model_cl\n",
    "from tools.data import unfold_raw, rm_repeated_annotations\n",
    "from tools.load_data import load_data\n",
    "\n",
    "from models.eeg_encoder import EEGEncoder\n",
    "from models.envelope_encoder import EnvelopeEncoder\n",
    "from models.contrastive_eeg_speech import CLEE\n",
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read the command-line argument passed to the interpreter when invoking the script\n",
    "lr = 0.001#sys.argv[1]\n",
    "batch_size = 256# sys.argv[2]\n",
    "\n",
    "\n",
    "# Read data\n",
    "subj_ids = list(range(1, 20))\n",
    "fs = 128\n",
    "window_size = int(5 * fs)\n",
    "stride_size_train, stride_size_val, stride_size_test = int(2.5 * fs), int(5 * fs), int(5 * fs)\n",
    "batch_size = int(batch_size)\n",
    "lr = lr\n",
    "\n",
    "n_channs = 129 # 128 for eeg, 1 for env\n",
    "print('-------------------------------------')\n",
    "print(f'window_size: {window_size}  stride_size_test: {stride_size_test}')\n",
    "\n",
    "dataset_name = ['rochester_data', 'natural_speech']\n",
    "outputs_path = f'../outputs/'\n",
    "data_path = os.path.join(outputs_path, dataset_name[0], dataset_name[1])\n",
    "after_ica_path = os.path.join(data_path, 'after_ica_raw')\n",
    "print(f'data_path: {data_path}')\n",
    "\n",
    "\n",
    "X = load_data(subj_ids, after_ica_path, window_size, \n",
    "              stride_size_train, stride_size_val, stride_size_test, n_channs)\n",
    "\n",
    "\n",
    "# Create dataloaders\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, eeg, env):\n",
    "        self.eeg = eeg\n",
    "        self.env = env\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.eeg[index], self.env[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.eeg)\n",
    "    \n",
    "\n",
    "dataset_train = MyDataset(X['eegs_train'], X['envs_train'])\n",
    "dl_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "dl_val = DataLoader(MyDataset(X[\"eegs_val\"], X[\"envs_val\"]), \n",
    "                    batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "# Create model\n",
    "eeg_encoder = EEGEncoder()\n",
    "env_encoder = EnvelopeEncoder()\n",
    "model = CLEE(eeg_encoder, env_encoder)\n",
    "model.to(device)\n",
    "\n",
    "# Train model\n",
    "models_dict = {f'lr_{lr}_bs_{batch_size}': model}\n",
    "lossi = []\n",
    "udri = [] # update / data ratio \n",
    "ud = []\n",
    "\n",
    "\n",
    "\n",
    "for name, model in models_dict.items():\n",
    "\n",
    "    # Reset for the new model in the loop\n",
    "    print(f\"+--------------New model: {name}----------------------+\")\n",
    "    writer = SummaryWriter(log_dir=f\"runs/{name}_{time.strftime('%Y%m%d_%H%M%S')}\")\n",
    "    model.to(device)\n",
    "    optimizer = optim.NAdam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.7)\n",
    "    cnt = 0\n",
    "    loss_batches = []\n",
    "\n",
    "\n",
    "    for epoch in range(1, 400):\n",
    "\n",
    "        print(f\"====== Epoch: {epoch}\")\n",
    "\n",
    "        model.train()\n",
    "        for ix_batch, (Xb_eeg, Xb_env) in enumerate(dl_train):\n",
    "\n",
    "            # send to device\n",
    "            Xb_eeg = Xb_eeg.to(device)\n",
    "            Xb_env = Xb_env.to(device)\n",
    "\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            eeg_features, env_features, logit_scale = model(Xb_eeg, Xb_env) \n",
    "\n",
    "\n",
    "            # normalize features\n",
    "            eeg_features_n = eeg_features / eeg_features.norm(dim=1, keepdim=True)\n",
    "            env_features_n = env_features / env_features.norm(dim=1, keepdim=True)\n",
    "\n",
    "            # logits\n",
    "            logits_per_eeg = logit_scale * eeg_features_n @ env_features_n.t()\n",
    "            logits_per_env = logits_per_eeg.t()\n",
    "\n",
    "            #loss function\n",
    "            labels = torch.arange(batch_size).to(device)\n",
    "            loss_eeg = F.cross_entropy(logits_per_eeg, labels)\n",
    "            loss_env = F.cross_entropy(logits_per_env, labels)\n",
    "            loss   = (loss_eeg + loss_env)/2\n",
    "\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_batches.append(loss.item())\n",
    "            cnt += 1\n",
    "\n",
    "            with torch.no_grad():\n",
    "                #ud = {f\"p{ix}\":(lr*p.grad.std() / p.data.std()).log10().item() for ix, p in enumerate(model.parameters()) if p.ndim==4 }\n",
    "                #writer.add_scalars('UpdateOData/ud', ud, cnt)\n",
    "                writer.add_scalar('Loss/train_batch', loss.item(), cnt)\n",
    "\n",
    "            # normalize weights\n",
    "            with torch.no_grad():\n",
    "                model.eeg_encoder.normalize_weights()\n",
    "            \n",
    "            #break   \n",
    "\n",
    "        loss_epoch = loss_batches[-(ix_batch + 1):]  # mean loss across batches\n",
    "        loss_epoch = sum(loss_epoch) / len(loss_epoch)\n",
    "        writer.add_scalar('Loss/train_epoch', loss_epoch, epoch)\n",
    "        #for pname, p in model.named_parameters():\n",
    "        #writer.add_histogram(f'Params/{pname}', p, epoch)\n",
    "        #writer.add_histogram(f'Grads/{pname}', p.grad, epoch)\n",
    "\n",
    "        loss_val, *_ = eval_model_cl(dl_val, model, device=device)\n",
    "        writer.add_scalar('Loss/val_epoch', loss_val, epoch)\n",
    "\n",
    "        \n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # Update learning rate based on epoch\n",
    "        scheduler.step()\n",
    "            \n",
    "    #break   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
