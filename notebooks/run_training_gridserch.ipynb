{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"V9GXcBGFsH7M","executionInfo":{"status":"ok","timestamp":1677916418308,"user_tz":-60,"elapsed":305,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":570,"referenced_widgets":["5d23a32b5d144a4eb1b6ac8d70e85626","c65664b7079942faaa4b463ee45797ac"]},"id":"Y4oavag4sH7N","executionInfo":{"status":"ok","timestamp":1677916427338,"user_tz":-60,"elapsed":8670,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"}},"outputId":"29177687-f56b-4421-c86f-02340bd29eb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["['.git', '.DS_Store', '.gitignore', 'EEG', 'LICENSE', 'train_cl_eeg2speech_rochester_v1.ipynb', 'train_cl_eeg2speech_rochester_v2.ipynb', '.ipynb_checkpoints', 'train_cl_eeg2speech_rochester_v3_test_old.ipynb', 'runs', 'train_cl_eeg2speech_rochester_v3_test.ipynb', 'train_cl_eeg2speech_rochester_v4_gridseaerch.ipynb', 'train_cl_eeg2speech_2.ipynb', 'train_cl_eeg2speech_rochester_subj_2.ipynb', 'README.md', 'train_eeg2speech_rochester.ipynb', 'train_cl_eeg2speech_rochester_v3.ipynb', 'models', 'run_training_gridsearch.py', 'tools', 'train_cl_eeg2speech_rochester_gridsearch.ipynb', 'train_cl_eeg2speech_rochester_gridsearch_test.ipynb', 'train_cl_eeg2speech_rochester_v4_gridsearch.ipynb', 'run_training_gridserch.ipynb']\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n","Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n","To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"]},{"output_type":"display_data","data":{"text/plain":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Collecting mne\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Collecting mne\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  Downloading mne-1.3.1-py3-none-any.whl (7.6 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Downloading mne-1.3.1-py3-none-any.whl (7.6 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d23a32b5d144a4eb1b6ac8d70e85626"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.8/dist-packages (from mne) (1.7.0)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: pooch&gt;=1.5 in /usr/local/lib/python3.8/dist-packages (from mne) (1.7.0)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from mne) (4.4.2)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from mne) (4.4.2)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mne) (3.5.3)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mne) (3.5.3)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from mne) (4.64.1)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from mne) (4.64.1)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from mne) (1.10.1)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: scipy&gt;=1.1.0 in /usr/local/lib/python3.8/dist-packages (from mne) (1.10.1)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mne) (23.0)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mne) (23.0)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from mne) (3.1.2)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from mne) (3.1.2)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.8/dist-packages (from mne) (1.22.4)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: numpy&gt;=1.15.4 in /usr/local/lib/python3.8/dist-packages (from mne) (1.22.4)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.5->mne) (3.0.0)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: platformdirs&gt;=2.5.0 in /usr/local/lib/python3.8/dist-packages (from pooch&gt;=1.5-&gt;mne) (3.0.0)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.5->mne) (2.25.1)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: requests&gt;=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch&gt;=1.5-&gt;mne) (2.25.1)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->mne) (2.1.2)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2-&gt;mne) (2.1.2)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (1.4.4)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (1.4.4)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (3.0.9)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: pyparsing&gt;=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (3.0.9)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (4.38.0)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (4.38.0)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (2.8.2)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (2.8.2)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (8.4.0)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (8.4.0)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (0.11.0)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (0.11.0)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->mne) (1.15.0)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib-&gt;mne) (1.15.0)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (4.0.0)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.5-&gt;mne) (4.0.0)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.14)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.5-&gt;mne) (1.26.14)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.5-&gt;mne) (2.10)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.12.7)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.5-&gt;mne) (2022.12.7)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Installing collected packages: mne\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Installing collected packages: mne\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Successfully installed mne-1.3.1\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully installed mne-1.3.1\n","</pre>\n"]},"metadata":{}}],"source":["\n","import os\n","import sys\n","\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"Colab Notebooks/prj_neuroread_analysis/neuroread/\"\n","GOOGLE_DRIVE_PATH = os.path.join(\"/content\", \"drive\", \"MyDrive\", GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","\n","# Add to sys so we can import .py files.\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","os.chdir(GOOGLE_DRIVE_PATH)\n","\n","# Install unavailable packages\n","import pip\n","def import_or_install(package):\n","    try:\n","        __import__(package)\n","    except ImportError:\n","        pip.main(['install', package])\n","\n","import_or_install(\"mne\")\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXZzZce9t49N","executionInfo":{"status":"ok","timestamp":1677916429209,"user_tz":-60,"elapsed":1878,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"}},"outputId":"6bd34cf9-66ae-487e-f304-a4ab42d338b3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"7lXE3PqdsH7O","executionInfo":{"status":"ok","timestamp":1677916429210,"user_tz":-60,"elapsed":15,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FVG0hQV6sH7P","executionInfo":{"status":"ok","timestamp":1677916429956,"user_tz":-60,"elapsed":753,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"}},"outputId":"bd3c29b0-7a34-418c-8a5c-3c4c6b8b4368"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 89.6 gigabytes of available RAM\n","\n","Sat Mar  4 07:53:49 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    48W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n"," print('Not connected to a GPU')\n","else:\n"," print(gpu_info)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4T_-IJ1psH7P","executionInfo":{"status":"ok","timestamp":1677916436977,"user_tz":-60,"elapsed":7023,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"}},"outputId":"ec296c3e-1827-45f1-c5e7-aa2517c98fe7"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["import os, sys, glob\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import numpy as np\n","\n","import mne\n","import time\n","\n","\n","from torchsummary import summary\n","from torch.utils.tensorboard import SummaryWriter\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","from tools.train import eval_model_cl\n","from tools.data import unfold_raw, rm_repeated_annotations\n","from tools.load_data import load_data\n","\n","from models.eeg_encoder import EEGEncoder\n","from models.envelope_encoder import EnvelopeEncoder\n","from models.contrastive_eeg_speech import CLEE\n","# -------------------------------------"]},{"cell_type":"code","source":[],"metadata":{"id":"uJ5O0IHQvbBG","executionInfo":{"status":"ok","timestamp":1677916436978,"user_tz":-60,"elapsed":9,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"H6PuqpvYsH7P","executionInfo":{"status":"ok","timestamp":1677923311182,"user_tz":-60,"elapsed":1419294,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"}},"outputId":"84bf617d-4856-4d21-f43c-1e4c519105b8"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["-------------------------------------\n","window_size: 640  stride_size_test: 640\n","data_path: ../outputs/rochester_data/natural_speech\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_1_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 48  Num of removed annots: 19  Num of retained annots:  29\n","-------------------------------------\n","N train: 26  N val: 1  N test: 1\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_2_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 65  Num of removed annots: 19  Num of retained annots:  46\n","-------------------------------------\n","N train: 68  N val: 2  N test: 2\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_3_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 47  Num of removed annots: 19  Num of retained annots:  28\n","-------------------------------------\n","N train: 93  N val: 3  N test: 3\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_4_after_ica_raw.fif...\n","    Range : 0 ... 464394 =      0.000 ...  3628.078 secs\n","Ready.\n","Reading 0 ... 464394  =      0.000 ...  3628.078 secs...\n","Initial num of annots: 41  Num of removed annots: 19  Num of retained annots:  22\n","-------------------------------------\n","N train: 112  N val: 4  N test: 4\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_5_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 41  Num of removed annots: 19  Num of retained annots:  22\n","-------------------------------------\n","N train: 131  N val: 5  N test: 5\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_6_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 58  Num of removed annots: 19  Num of retained annots:  39\n","-------------------------------------\n","N train: 167  N val: 6  N test: 6\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_7_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 74  Num of removed annots: 18  Num of retained annots:  56\n","-------------------------------------\n","N train: 220  N val: 7  N test: 7\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_8_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 42  Num of removed annots: 19  Num of retained annots:  23\n","-------------------------------------\n","N train: 240  N val: 8  N test: 8\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_9_after_ica_raw.fif...\n","    Range : 0 ... 464396 =      0.000 ...  3628.094 secs\n","Ready.\n","Reading 0 ... 464396  =      0.000 ...  3628.094 secs...\n","Initial num of annots: 50  Num of removed annots: 19  Num of retained annots:  31\n","-------------------------------------\n","N train: 268  N val: 9  N test: 9\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_10_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 69  Num of removed annots: 18  Num of retained annots:  51\n","-------------------------------------\n","N train: 315  N val: 10  N test: 10\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_11_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 78  Num of removed annots: 19  Num of retained annots:  59\n","-------------------------------------\n","N train: 371  N val: 11  N test: 11\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_12_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 51  Num of removed annots: 19  Num of retained annots:  32\n","-------------------------------------\n","N train: 400  N val: 12  N test: 12\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_13_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 41  Num of removed annots: 19  Num of retained annots:  22\n","-------------------------------------\n","N train: 419  N val: 13  N test: 13\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_14_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 39  Num of removed annots: 19  Num of retained annots:  20\n","-------------------------------------\n","N train: 436  N val: 14  N test: 14\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_15_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 58  Num of removed annots: 17  Num of retained annots:  41\n","-------------------------------------\n","N train: 474  N val: 15  N test: 15\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_16_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 67  Num of removed annots: 19  Num of retained annots:  48\n","-------------------------------------\n","N train: 519  N val: 16  N test: 16\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_17_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 41  Num of removed annots: 19  Num of retained annots:  22\n","-------------------------------------\n","N train: 538  N val: 17  N test: 17\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_18_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 73  Num of removed annots: 19  Num of retained annots:  54\n","-------------------------------------\n","N train: 589  N val: 18  N test: 18\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_19_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 63  Num of removed annots: 19  Num of retained annots:  44\n","-------------------------------------\n","N train: 630  N val: 19  N test: 19\n","Shape Trian: torch.Size([21765, 1, 129, 640])  Shape Val: torch.Size([714, 1, 129, 640])  Shape Test: torch.Size([685, 1, 129, 640])\n","-------------------------------------\n","Shape EEG Train: torch.Size([21765, 1, 128, 640])  Val: torch.Size([714, 1, 128, 640])  Test: torch.Size([685, 1, 128, 640])\n","Mean: 6.165832427962314e-11  Std: 5.718287411582423e-06\n","Shape Env Train: torch.Size([21765, 1, 1, 640])  Val: torch.Size([714, 1, 1, 640])  Test: torch.Size([685, 1, 1, 640])\n","Mean Env: 2.3698980808258057  Std Env: 2.5990054607391357\n","+--------------New model: lr_0.001_bs_64----------------------+\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","</pre>\n"],"text/plain":["Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">NumExpr defaulting to 8 threads.\n","</pre>\n"],"text/plain":["NumExpr defaulting to 8 threads.\n"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["====== Epoch: 1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]},{"output_type":"stream","name":"stdout","text":["====> Validation loss: 4.0448,  X1 loss: 4.0306   X2 loss: 4.0591\n","====== Epoch: 2\n","====> Validation loss: 3.9165,  X1 loss: 3.9073   X2 loss: 3.9258\n","====== Epoch: 3\n","====> Validation loss: 3.8540,  X1 loss: 3.8411   X2 loss: 3.8669\n","====== Epoch: 4\n","====> Validation loss: 3.8241,  X1 loss: 3.8112   X2 loss: 3.8370\n","====== Epoch: 5\n","====> Validation loss: 3.7721,  X1 loss: 3.7609   X2 loss: 3.7833\n","====== Epoch: 6\n","====> Validation loss: 3.7368,  X1 loss: 3.7317   X2 loss: 3.7419\n","====== Epoch: 7\n","====> Validation loss: 3.7208,  X1 loss: 3.7148   X2 loss: 3.7268\n","====== Epoch: 8\n","====> Validation loss: 3.7135,  X1 loss: 3.7018   X2 loss: 3.7252\n","====== Epoch: 9\n","====> Validation loss: 3.7112,  X1 loss: 3.6989   X2 loss: 3.7235\n","====== Epoch: 10\n","====> Validation loss: 3.6966,  X1 loss: 3.6860   X2 loss: 3.7071\n","====== Epoch: 11\n","====> Validation loss: 3.6853,  X1 loss: 3.6771   X2 loss: 3.6934\n","====== Epoch: 12\n","====> Validation loss: 3.7226,  X1 loss: 3.7076   X2 loss: 3.7376\n","====== Epoch: 13\n","====> Validation loss: 3.6780,  X1 loss: 3.6686   X2 loss: 3.6875\n","====== Epoch: 14\n","====> Validation loss: 3.6461,  X1 loss: 3.6301   X2 loss: 3.6621\n","====== Epoch: 15\n","====> Validation loss: 3.6634,  X1 loss: 3.6467   X2 loss: 3.6801\n","====== Epoch: 16\n","====> Validation loss: 3.6544,  X1 loss: 3.6383   X2 loss: 3.6705\n","====== Epoch: 17\n","====> Validation loss: 3.6424,  X1 loss: 3.6252   X2 loss: 3.6596\n","====== Epoch: 18\n","====> Validation loss: 3.6424,  X1 loss: 3.6278   X2 loss: 3.6570\n","====== Epoch: 19\n","====> Validation loss: 3.6354,  X1 loss: 3.6222   X2 loss: 3.6485\n","====== Epoch: 20\n","====> Validation loss: 3.6230,  X1 loss: 3.6093   X2 loss: 3.6368\n","====== Epoch: 21\n","====> Validation loss: 3.5804,  X1 loss: 3.5662   X2 loss: 3.5946\n","====== Epoch: 22\n","====> Validation loss: 3.5961,  X1 loss: 3.5840   X2 loss: 3.6082\n","====== Epoch: 23\n","====> Validation loss: 3.5824,  X1 loss: 3.5607   X2 loss: 3.6041\n","====== Epoch: 24\n","====> Validation loss: 3.6165,  X1 loss: 3.5989   X2 loss: 3.6341\n","====== Epoch: 25\n","====> Validation loss: 3.5677,  X1 loss: 3.5537   X2 loss: 3.5817\n","====== Epoch: 26\n","====> Validation loss: 3.5911,  X1 loss: 3.5739   X2 loss: 3.6082\n","====== Epoch: 27\n","====> Validation loss: 3.6035,  X1 loss: 3.5878   X2 loss: 3.6192\n","====== Epoch: 28\n","====> Validation loss: 3.5763,  X1 loss: 3.5527   X2 loss: 3.5998\n","====== Epoch: 29\n","====> Validation loss: 3.6158,  X1 loss: 3.5952   X2 loss: 3.6364\n","====== Epoch: 30\n","====> Validation loss: 3.5412,  X1 loss: 3.5208   X2 loss: 3.5615\n","====== Epoch: 31\n","====> Validation loss: 3.5209,  X1 loss: 3.5071   X2 loss: 3.5347\n","====== Epoch: 32\n","====> Validation loss: 3.5125,  X1 loss: 3.4956   X2 loss: 3.5293\n","====== Epoch: 33\n","====> Validation loss: 3.5469,  X1 loss: 3.5357   X2 loss: 3.5582\n","====== Epoch: 34\n","====> Validation loss: 3.5191,  X1 loss: 3.5013   X2 loss: 3.5369\n","====== Epoch: 35\n","====> Validation loss: 3.5146,  X1 loss: 3.4993   X2 loss: 3.5300\n","====== Epoch: 36\n","====> Validation loss: 3.5336,  X1 loss: 3.5153   X2 loss: 3.5518\n","====== Epoch: 37\n","====> Validation loss: 3.5332,  X1 loss: 3.5116   X2 loss: 3.5547\n","====== Epoch: 38\n","====> Validation loss: 3.5091,  X1 loss: 3.4927   X2 loss: 3.5255\n","====== Epoch: 39\n","====> Validation loss: 3.4791,  X1 loss: 3.4592   X2 loss: 3.4989\n","====== Epoch: 40\n","====> Validation loss: 3.4767,  X1 loss: 3.4552   X2 loss: 3.4983\n","====== Epoch: 41\n","====> Validation loss: 3.5085,  X1 loss: 3.4885   X2 loss: 3.5284\n","====== Epoch: 42\n","====> Validation loss: 3.4942,  X1 loss: 3.4800   X2 loss: 3.5084\n","====== Epoch: 43\n","====> Validation loss: 3.4853,  X1 loss: 3.4698   X2 loss: 3.5008\n","====== Epoch: 44\n","====> Validation loss: 3.4672,  X1 loss: 3.4508   X2 loss: 3.4836\n","====== Epoch: 45\n","====> Validation loss: 3.4889,  X1 loss: 3.4657   X2 loss: 3.5120\n","====== Epoch: 46\n","====> Validation loss: 3.4607,  X1 loss: 3.4409   X2 loss: 3.4805\n","====== Epoch: 47\n","====> Validation loss: 3.4988,  X1 loss: 3.4841   X2 loss: 3.5135\n","====== Epoch: 48\n","====> Validation loss: 3.4809,  X1 loss: 3.4600   X2 loss: 3.5018\n","====== Epoch: 49\n","====> Validation loss: 3.4636,  X1 loss: 3.4473   X2 loss: 3.4799\n","====== Epoch: 50\n","====> Validation loss: 3.4389,  X1 loss: 3.4239   X2 loss: 3.4538\n","====== Epoch: 51\n","====> Validation loss: 3.4690,  X1 loss: 3.4533   X2 loss: 3.4848\n","====== Epoch: 52\n","====> Validation loss: 3.4459,  X1 loss: 3.4300   X2 loss: 3.4618\n","====== Epoch: 53\n","====> Validation loss: 3.4574,  X1 loss: 3.4475   X2 loss: 3.4673\n","====== Epoch: 54\n","====> Validation loss: 3.4280,  X1 loss: 3.4120   X2 loss: 3.4440\n","====== Epoch: 55\n","====> Validation loss: 3.4116,  X1 loss: 3.3985   X2 loss: 3.4247\n","====== Epoch: 56\n","====> Validation loss: 3.4453,  X1 loss: 3.4244   X2 loss: 3.4662\n","====== Epoch: 57\n","====> Validation loss: 3.4386,  X1 loss: 3.4202   X2 loss: 3.4570\n","====== Epoch: 58\n","====> Validation loss: 3.4500,  X1 loss: 3.4346   X2 loss: 3.4654\n","====== Epoch: 59\n","====> Validation loss: 3.4668,  X1 loss: 3.4459   X2 loss: 3.4876\n","====== Epoch: 60\n","====> Validation loss: 3.4520,  X1 loss: 3.4376   X2 loss: 3.4664\n","====== Epoch: 61\n","====> Validation loss: 3.4312,  X1 loss: 3.4157   X2 loss: 3.4468\n","====== Epoch: 62\n","====> Validation loss: 3.4180,  X1 loss: 3.4059   X2 loss: 3.4300\n","====== Epoch: 63\n","====> Validation loss: 3.4417,  X1 loss: 3.4233   X2 loss: 3.4601\n","====== Epoch: 64\n","====> Validation loss: 3.4273,  X1 loss: 3.4080   X2 loss: 3.4466\n","====== Epoch: 65\n","====> Validation loss: 3.4470,  X1 loss: 3.4241   X2 loss: 3.4699\n","====== Epoch: 66\n","====> Validation loss: 3.4099,  X1 loss: 3.3967   X2 loss: 3.4230\n","====== Epoch: 67\n","====> Validation loss: 3.4406,  X1 loss: 3.4254   X2 loss: 3.4557\n","====== Epoch: 68\n","====> Validation loss: 3.4697,  X1 loss: 3.4479   X2 loss: 3.4916\n","====== Epoch: 69\n","====> Validation loss: 3.4527,  X1 loss: 3.4358   X2 loss: 3.4697\n","====== Epoch: 70\n","====> Validation loss: 3.4486,  X1 loss: 3.4303   X2 loss: 3.4669\n","====== Epoch: 71\n","====> Validation loss: 3.4202,  X1 loss: 3.3996   X2 loss: 3.4409\n","====== Epoch: 72\n","====> Validation loss: 3.4080,  X1 loss: 3.3884   X2 loss: 3.4276\n","====== Epoch: 73\n","====> Validation loss: 3.4130,  X1 loss: 3.4011   X2 loss: 3.4250\n","====== Epoch: 74\n","====> Validation loss: 3.4489,  X1 loss: 3.4315   X2 loss: 3.4663\n","====== Epoch: 75\n","====> Validation loss: 3.4039,  X1 loss: 3.3916   X2 loss: 3.4161\n","====== Epoch: 76\n","====> Validation loss: 3.4088,  X1 loss: 3.3900   X2 loss: 3.4276\n","====== Epoch: 77\n","====> Validation loss: 3.4194,  X1 loss: 3.4051   X2 loss: 3.4338\n","====== Epoch: 78\n","====> Validation loss: 3.3932,  X1 loss: 3.3769   X2 loss: 3.4095\n","====== Epoch: 79\n","====> Validation loss: 3.4079,  X1 loss: 3.3942   X2 loss: 3.4217\n","====== Epoch: 80\n","====> Validation loss: 3.4166,  X1 loss: 3.3958   X2 loss: 3.4373\n","====== Epoch: 81\n","====> Validation loss: 3.3901,  X1 loss: 3.3738   X2 loss: 3.4064\n","====== Epoch: 82\n","====> Validation loss: 3.3838,  X1 loss: 3.3595   X2 loss: 3.4081\n","====== Epoch: 83\n","====> Validation loss: 3.4049,  X1 loss: 3.3924   X2 loss: 3.4174\n","====== Epoch: 84\n","====> Validation loss: 3.3898,  X1 loss: 3.3689   X2 loss: 3.4107\n","====== Epoch: 85\n","====> Validation loss: 3.4256,  X1 loss: 3.4116   X2 loss: 3.4396\n","====== Epoch: 86\n","====> Validation loss: 3.3899,  X1 loss: 3.3711   X2 loss: 3.4087\n","====== Epoch: 87\n","====> Validation loss: 3.4051,  X1 loss: 3.3883   X2 loss: 3.4218\n","====== Epoch: 88\n","====> Validation loss: 3.3714,  X1 loss: 3.3521   X2 loss: 3.3907\n","====== Epoch: 89\n","====> Validation loss: 3.4068,  X1 loss: 3.3851   X2 loss: 3.4286\n","====== Epoch: 90\n","====> Validation loss: 3.3841,  X1 loss: 3.3652   X2 loss: 3.4031\n","====== Epoch: 91\n","====> Validation loss: 3.4218,  X1 loss: 3.4007   X2 loss: 3.4429\n","====== Epoch: 92\n","====> Validation loss: 3.3999,  X1 loss: 3.3782   X2 loss: 3.4216\n","====== Epoch: 93\n","====> Validation loss: 3.3792,  X1 loss: 3.3567   X2 loss: 3.4017\n","====== Epoch: 94\n","====> Validation loss: 3.3831,  X1 loss: 3.3661   X2 loss: 3.4000\n","====== Epoch: 95\n","====> Validation loss: 3.3748,  X1 loss: 3.3573   X2 loss: 3.3922\n","====== Epoch: 96\n","====> Validation loss: 3.3756,  X1 loss: 3.3517   X2 loss: 3.3995\n","====== Epoch: 97\n","====> Validation loss: 3.3541,  X1 loss: 3.3329   X2 loss: 3.3753\n","====== Epoch: 98\n","====> Validation loss: 3.3798,  X1 loss: 3.3637   X2 loss: 3.3958\n","====== Epoch: 99\n","====> Validation loss: 3.3668,  X1 loss: 3.3469   X2 loss: 3.3867\n","====== Epoch: 100\n","====> Validation loss: 3.3853,  X1 loss: 3.3717   X2 loss: 3.3989\n","====== Epoch: 101\n","====> Validation loss: 3.3722,  X1 loss: 3.3439   X2 loss: 3.4005\n","====== Epoch: 102\n","====> Validation loss: 3.3748,  X1 loss: 3.3562   X2 loss: 3.3934\n","====== Epoch: 103\n","====> Validation loss: 3.3734,  X1 loss: 3.3534   X2 loss: 3.3934\n","====== Epoch: 104\n","====> Validation loss: 3.3726,  X1 loss: 3.3552   X2 loss: 3.3901\n","====== Epoch: 105\n","====> Validation loss: 3.3922,  X1 loss: 3.3795   X2 loss: 3.4050\n","====== Epoch: 106\n","====> Validation loss: 3.3230,  X1 loss: 3.3056   X2 loss: 3.3404\n","====== Epoch: 107\n","====> Validation loss: 3.4088,  X1 loss: 3.3882   X2 loss: 3.4293\n","====== Epoch: 108\n","====> Validation loss: 3.3812,  X1 loss: 3.3566   X2 loss: 3.4059\n","====== Epoch: 109\n","====> Validation loss: 3.3243,  X1 loss: 3.3078   X2 loss: 3.3408\n","====== Epoch: 110\n","====> Validation loss: 3.4106,  X1 loss: 3.3940   X2 loss: 3.4272\n","====== Epoch: 111\n","====> Validation loss: 3.4010,  X1 loss: 3.3852   X2 loss: 3.4167\n","====== Epoch: 112\n","====> Validation loss: 3.3896,  X1 loss: 3.3701   X2 loss: 3.4091\n","====== Epoch: 113\n","====> Validation loss: 3.3826,  X1 loss: 3.3698   X2 loss: 3.3954\n","====== Epoch: 114\n","====> Validation loss: 3.3868,  X1 loss: 3.3686   X2 loss: 3.4051\n","====== Epoch: 115\n","====> Validation loss: 3.3459,  X1 loss: 3.3334   X2 loss: 3.3585\n","====== Epoch: 116\n","====> Validation loss: 3.3729,  X1 loss: 3.3599   X2 loss: 3.3859\n","====== Epoch: 117\n","====> Validation loss: 3.4038,  X1 loss: 3.3920   X2 loss: 3.4156\n","====== Epoch: 118\n","====> Validation loss: 3.4044,  X1 loss: 3.3838   X2 loss: 3.4251\n","====== Epoch: 119\n","====> Validation loss: 3.3612,  X1 loss: 3.3417   X2 loss: 3.3806\n","====== Epoch: 120\n","====> Validation loss: 3.3894,  X1 loss: 3.3751   X2 loss: 3.4038\n","====== Epoch: 121\n","====> Validation loss: 3.3740,  X1 loss: 3.3558   X2 loss: 3.3923\n","====== Epoch: 122\n","====> Validation loss: 3.3347,  X1 loss: 3.3190   X2 loss: 3.3504\n","====== Epoch: 123\n","====> Validation loss: 3.4031,  X1 loss: 3.3890   X2 loss: 3.4172\n","====== Epoch: 124\n","====> Validation loss: 3.3674,  X1 loss: 3.3479   X2 loss: 3.3868\n","====== Epoch: 125\n","====> Validation loss: 3.4033,  X1 loss: 3.3809   X2 loss: 3.4257\n","====== Epoch: 126\n","====> Validation loss: 3.3603,  X1 loss: 3.3492   X2 loss: 3.3713\n","====== Epoch: 127\n","====> Validation loss: 3.3902,  X1 loss: 3.3687   X2 loss: 3.4117\n","====== Epoch: 128\n","====> Validation loss: 3.3497,  X1 loss: 3.3342   X2 loss: 3.3653\n","====== Epoch: 129\n","====> Validation loss: 3.3695,  X1 loss: 3.3603   X2 loss: 3.3787\n","====== Epoch: 130\n","====> Validation loss: 3.3726,  X1 loss: 3.3573   X2 loss: 3.3879\n","====== Epoch: 131\n","====> Validation loss: 3.3515,  X1 loss: 3.3340   X2 loss: 3.3690\n","====== Epoch: 132\n","====> Validation loss: 3.3501,  X1 loss: 3.3320   X2 loss: 3.3682\n","====== Epoch: 133\n","====> Validation loss: 3.3465,  X1 loss: 3.3312   X2 loss: 3.3618\n","====== Epoch: 134\n","====> Validation loss: 3.3394,  X1 loss: 3.3149   X2 loss: 3.3639\n","====== Epoch: 135\n","====> Validation loss: 3.3543,  X1 loss: 3.3341   X2 loss: 3.3744\n","====== Epoch: 136\n","====> Validation loss: 3.3502,  X1 loss: 3.3367   X2 loss: 3.3637\n","====== Epoch: 137\n","====> Validation loss: 3.3924,  X1 loss: 3.3767   X2 loss: 3.4082\n","====== Epoch: 138\n","====> Validation loss: 3.3601,  X1 loss: 3.3386   X2 loss: 3.3817\n","====== Epoch: 139\n","====> Validation loss: 3.3813,  X1 loss: 3.3643   X2 loss: 3.3982\n","====== Epoch: 140\n","====> Validation loss: 3.3798,  X1 loss: 3.3666   X2 loss: 3.3929\n","====== Epoch: 141\n","====> Validation loss: 3.3767,  X1 loss: 3.3577   X2 loss: 3.3956\n","====== Epoch: 142\n","====> Validation loss: 3.3970,  X1 loss: 3.3761   X2 loss: 3.4180\n","====== Epoch: 143\n","====> Validation loss: 3.3508,  X1 loss: 3.3374   X2 loss: 3.3642\n","====== Epoch: 144\n","====> Validation loss: 3.3823,  X1 loss: 3.3695   X2 loss: 3.3951\n","====== Epoch: 145\n","====> Validation loss: 3.3311,  X1 loss: 3.3159   X2 loss: 3.3463\n","====== Epoch: 146\n","====> Validation loss: 3.3859,  X1 loss: 3.3680   X2 loss: 3.4037\n","====== Epoch: 147\n","====> Validation loss: 3.3928,  X1 loss: 3.3727   X2 loss: 3.4129\n","====== Epoch: 148\n","====> Validation loss: 3.3252,  X1 loss: 3.3109   X2 loss: 3.3396\n","====== Epoch: 149\n","====> Validation loss: 3.3489,  X1 loss: 3.3307   X2 loss: 3.3671\n","====== Epoch: 150\n","====> Validation loss: 3.3583,  X1 loss: 3.3447   X2 loss: 3.3719\n","====== Epoch: 151\n","====> Validation loss: 3.3464,  X1 loss: 3.3289   X2 loss: 3.3639\n","====== Epoch: 152\n","====> Validation loss: 3.3692,  X1 loss: 3.3551   X2 loss: 3.3834\n","====== Epoch: 153\n","====> Validation loss: 3.3455,  X1 loss: 3.3216   X2 loss: 3.3694\n","====== Epoch: 154\n","====> Validation loss: 3.3636,  X1 loss: 3.3497   X2 loss: 3.3775\n","====== Epoch: 155\n","====> Validation loss: 3.3435,  X1 loss: 3.3270   X2 loss: 3.3599\n","====== Epoch: 156\n","====> Validation loss: 3.3792,  X1 loss: 3.3608   X2 loss: 3.3976\n","====== Epoch: 157\n","====> Validation loss: 3.3714,  X1 loss: 3.3544   X2 loss: 3.3883\n","====== Epoch: 158\n","====> Validation loss: 3.3554,  X1 loss: 3.3318   X2 loss: 3.3790\n","====== Epoch: 159\n","====> Validation loss: 3.3590,  X1 loss: 3.3446   X2 loss: 3.3733\n","====== Epoch: 160\n","====> Validation loss: 3.3360,  X1 loss: 3.3206   X2 loss: 3.3514\n","====== Epoch: 161\n","====> Validation loss: 3.3542,  X1 loss: 3.3387   X2 loss: 3.3697\n","====== Epoch: 162\n","====> Validation loss: 3.3546,  X1 loss: 3.3413   X2 loss: 3.3679\n","====== Epoch: 163\n","====> Validation loss: 3.3668,  X1 loss: 3.3472   X2 loss: 3.3864\n","====== Epoch: 164\n","====> Validation loss: 3.3377,  X1 loss: 3.3223   X2 loss: 3.3532\n","====== Epoch: 165\n","====> Validation loss: 3.3575,  X1 loss: 3.3401   X2 loss: 3.3749\n","====== Epoch: 166\n","====> Validation loss: 3.3283,  X1 loss: 3.3060   X2 loss: 3.3507\n","====== Epoch: 167\n","====> Validation loss: 3.3640,  X1 loss: 3.3479   X2 loss: 3.3802\n","====== Epoch: 168\n","====> Validation loss: 3.3879,  X1 loss: 3.3685   X2 loss: 3.4073\n","====== Epoch: 169\n","====> Validation loss: 3.3376,  X1 loss: 3.3176   X2 loss: 3.3576\n","====== Epoch: 170\n","====> Validation loss: 3.3607,  X1 loss: 3.3464   X2 loss: 3.3751\n","====== Epoch: 171\n","====> Validation loss: 3.3242,  X1 loss: 3.3043   X2 loss: 3.3440\n","====== Epoch: 172\n","====> Validation loss: 3.3584,  X1 loss: 3.3404   X2 loss: 3.3764\n","====== Epoch: 173\n","====> Validation loss: 3.3766,  X1 loss: 3.3555   X2 loss: 3.3978\n","====== Epoch: 174\n","====> Validation loss: 3.3884,  X1 loss: 3.3700   X2 loss: 3.4068\n","====== Epoch: 175\n","====> Validation loss: 3.3900,  X1 loss: 3.3705   X2 loss: 3.4095\n","====== Epoch: 176\n","====> Validation loss: 3.3461,  X1 loss: 3.3264   X2 loss: 3.3659\n","====== Epoch: 177\n","====> Validation loss: 3.3569,  X1 loss: 3.3338   X2 loss: 3.3800\n","====== Epoch: 178\n","====> Validation loss: 3.3715,  X1 loss: 3.3461   X2 loss: 3.3968\n","====== Epoch: 179\n","====> Validation loss: 3.3590,  X1 loss: 3.3383   X2 loss: 3.3797\n","====== Epoch: 180\n","====> Validation loss: 3.3228,  X1 loss: 3.3016   X2 loss: 3.3441\n","====== Epoch: 181\n","====> Validation loss: 3.3372,  X1 loss: 3.3261   X2 loss: 3.3483\n","====== Epoch: 182\n","====> Validation loss: 3.3507,  X1 loss: 3.3395   X2 loss: 3.3618\n","====== Epoch: 183\n","====> Validation loss: 3.3462,  X1 loss: 3.3236   X2 loss: 3.3688\n","====== Epoch: 184\n","====> Validation loss: 3.3384,  X1 loss: 3.3223   X2 loss: 3.3544\n","====== Epoch: 185\n","====> Validation loss: 3.3671,  X1 loss: 3.3481   X2 loss: 3.3860\n","====== Epoch: 186\n","====> Validation loss: 3.3479,  X1 loss: 3.3300   X2 loss: 3.3657\n","====== Epoch: 187\n","====> Validation loss: 3.3220,  X1 loss: 3.3080   X2 loss: 3.3361\n","====== Epoch: 188\n","====> Validation loss: 3.3532,  X1 loss: 3.3379   X2 loss: 3.3686\n","====== Epoch: 189\n","====> Validation loss: 3.3558,  X1 loss: 3.3372   X2 loss: 3.3743\n","====== Epoch: 190\n","====> Validation loss: 3.3526,  X1 loss: 3.3313   X2 loss: 3.3739\n","====== Epoch: 191\n","====> Validation loss: 3.3900,  X1 loss: 3.3715   X2 loss: 3.4085\n","====== Epoch: 192\n","====> Validation loss: 3.3937,  X1 loss: 3.3713   X2 loss: 3.4161\n","====== Epoch: 193\n","====> Validation loss: 3.3343,  X1 loss: 3.3148   X2 loss: 3.3539\n","====== Epoch: 194\n","====> Validation loss: 3.3494,  X1 loss: 3.3356   X2 loss: 3.3631\n","====== Epoch: 195\n","====> Validation loss: 3.3778,  X1 loss: 3.3630   X2 loss: 3.3926\n","====== Epoch: 196\n","====> Validation loss: 3.3522,  X1 loss: 3.3369   X2 loss: 3.3674\n","====== Epoch: 197\n","====> Validation loss: 3.3771,  X1 loss: 3.3644   X2 loss: 3.3898\n","====== Epoch: 198\n","====> Validation loss: 3.3714,  X1 loss: 3.3510   X2 loss: 3.3919\n","====== Epoch: 199\n","====> Validation loss: 3.3631,  X1 loss: 3.3446   X2 loss: 3.3817\n","====== Epoch: 200\n","====> Validation loss: 3.3500,  X1 loss: 3.3224   X2 loss: 3.3775\n","====== Epoch: 201\n","====> Validation loss: 3.3370,  X1 loss: 3.3094   X2 loss: 3.3645\n","====== Epoch: 202\n","====> Validation loss: 3.3649,  X1 loss: 3.3464   X2 loss: 3.3834\n","====== Epoch: 203\n","====> Validation loss: 3.3845,  X1 loss: 3.3697   X2 loss: 3.3993\n","====== Epoch: 204\n","====> Validation loss: 3.3336,  X1 loss: 3.3128   X2 loss: 3.3544\n","====== Epoch: 205\n","====> Validation loss: 3.3467,  X1 loss: 3.3285   X2 loss: 3.3648\n","====== Epoch: 206\n","====> Validation loss: 3.3471,  X1 loss: 3.3274   X2 loss: 3.3667\n","====== Epoch: 207\n","====> Validation loss: 3.3078,  X1 loss: 3.2942   X2 loss: 3.3213\n","====== Epoch: 208\n","====> Validation loss: 3.3282,  X1 loss: 3.3125   X2 loss: 3.3439\n","====== Epoch: 209\n","====> Validation loss: 3.3530,  X1 loss: 3.3377   X2 loss: 3.3684\n","====== Epoch: 210\n","====> Validation loss: 3.3320,  X1 loss: 3.3124   X2 loss: 3.3516\n","====== Epoch: 211\n","====> Validation loss: 3.3580,  X1 loss: 3.3384   X2 loss: 3.3777\n","====== Epoch: 212\n","====> Validation loss: 3.3618,  X1 loss: 3.3488   X2 loss: 3.3747\n","====== Epoch: 213\n","====> Validation loss: 3.3399,  X1 loss: 3.3267   X2 loss: 3.3531\n","====== Epoch: 214\n","====> Validation loss: 3.3655,  X1 loss: 3.3490   X2 loss: 3.3820\n","====== Epoch: 215\n","====> Validation loss: 3.3595,  X1 loss: 3.3411   X2 loss: 3.3779\n","====== Epoch: 216\n","====> Validation loss: 3.3662,  X1 loss: 3.3471   X2 loss: 3.3853\n","====== Epoch: 217\n","====> Validation loss: 3.3152,  X1 loss: 3.3022   X2 loss: 3.3282\n","====== Epoch: 218\n","====> Validation loss: 3.3609,  X1 loss: 3.3457   X2 loss: 3.3761\n","====== Epoch: 219\n","====> Validation loss: 3.3335,  X1 loss: 3.3152   X2 loss: 3.3517\n","====== Epoch: 220\n","====> Validation loss: 3.3386,  X1 loss: 3.3119   X2 loss: 3.3653\n","====== Epoch: 221\n","====> Validation loss: 3.3427,  X1 loss: 3.3231   X2 loss: 3.3623\n","====== Epoch: 222\n","====> Validation loss: 3.3464,  X1 loss: 3.3293   X2 loss: 3.3635\n","====== Epoch: 223\n","====> Validation loss: 3.3582,  X1 loss: 3.3418   X2 loss: 3.3745\n","====== Epoch: 224\n","====> Validation loss: 3.3527,  X1 loss: 3.3356   X2 loss: 3.3699\n","====== Epoch: 225\n","====> Validation loss: 3.3617,  X1 loss: 3.3408   X2 loss: 3.3827\n","====== Epoch: 226\n","====> Validation loss: 3.3284,  X1 loss: 3.3076   X2 loss: 3.3492\n","====== Epoch: 227\n","====> Validation loss: 3.3069,  X1 loss: 3.2866   X2 loss: 3.3272\n","====== Epoch: 228\n","====> Validation loss: 3.3983,  X1 loss: 3.3783   X2 loss: 3.4183\n","====== Epoch: 229\n","====> Validation loss: 3.3829,  X1 loss: 3.3695   X2 loss: 3.3964\n","====== Epoch: 230\n","====> Validation loss: 3.3642,  X1 loss: 3.3512   X2 loss: 3.3772\n","====== Epoch: 231\n","====> Validation loss: 3.3646,  X1 loss: 3.3510   X2 loss: 3.3783\n","====== Epoch: 232\n","====> Validation loss: 3.3421,  X1 loss: 3.3185   X2 loss: 3.3658\n","====== Epoch: 233\n","====> Validation loss: 3.3299,  X1 loss: 3.3120   X2 loss: 3.3479\n","====== Epoch: 234\n","====> Validation loss: 3.3172,  X1 loss: 3.2950   X2 loss: 3.3395\n","====== Epoch: 235\n","====> Validation loss: 3.3433,  X1 loss: 3.3265   X2 loss: 3.3602\n","====== Epoch: 236\n","====> Validation loss: 3.3439,  X1 loss: 3.3283   X2 loss: 3.3595\n","====== Epoch: 237\n","====> Validation loss: 3.3176,  X1 loss: 3.2971   X2 loss: 3.3380\n","====== Epoch: 238\n","====> Validation loss: 3.3481,  X1 loss: 3.3258   X2 loss: 3.3704\n","====== Epoch: 239\n","====> Validation loss: 3.3635,  X1 loss: 3.3433   X2 loss: 3.3838\n","====== Epoch: 240\n","====> Validation loss: 3.3458,  X1 loss: 3.3230   X2 loss: 3.3686\n","====== Epoch: 241\n","====> Validation loss: 3.3701,  X1 loss: 3.3530   X2 loss: 3.3872\n","====== Epoch: 242\n","====> Validation loss: 3.2995,  X1 loss: 3.2773   X2 loss: 3.3216\n","====== Epoch: 243\n","====> Validation loss: 3.3969,  X1 loss: 3.3718   X2 loss: 3.4220\n","====== Epoch: 244\n","====> Validation loss: 3.3541,  X1 loss: 3.3361   X2 loss: 3.3722\n","====== Epoch: 245\n","====> Validation loss: 3.3425,  X1 loss: 3.3294   X2 loss: 3.3557\n","====== Epoch: 246\n","====> Validation loss: 3.3464,  X1 loss: 3.3366   X2 loss: 3.3562\n","====== Epoch: 247\n","====> Validation loss: 3.3472,  X1 loss: 3.3288   X2 loss: 3.3656\n","====== Epoch: 248\n","====> Validation loss: 3.3412,  X1 loss: 3.3174   X2 loss: 3.3651\n","====== Epoch: 249\n","====> Validation loss: 3.3007,  X1 loss: 3.2839   X2 loss: 3.3175\n","====== Epoch: 250\n","====> Validation loss: 3.3408,  X1 loss: 3.3248   X2 loss: 3.3568\n","====== Epoch: 251\n","====> Validation loss: 3.3557,  X1 loss: 3.3348   X2 loss: 3.3766\n","====== Epoch: 252\n","====> Validation loss: 3.3497,  X1 loss: 3.3323   X2 loss: 3.3671\n","====== Epoch: 253\n","====> Validation loss: 3.3694,  X1 loss: 3.3543   X2 loss: 3.3844\n","====== Epoch: 254\n","====> Validation loss: 3.3563,  X1 loss: 3.3332   X2 loss: 3.3794\n","====== Epoch: 255\n","====> Validation loss: 3.3475,  X1 loss: 3.3333   X2 loss: 3.3617\n","====== Epoch: 256\n","====> Validation loss: 3.3355,  X1 loss: 3.3170   X2 loss: 3.3540\n","====== Epoch: 257\n","====> Validation loss: 3.3472,  X1 loss: 3.3338   X2 loss: 3.3606\n","====== Epoch: 258\n","====> Validation loss: 3.3541,  X1 loss: 3.3359   X2 loss: 3.3723\n","====== Epoch: 259\n","====> Validation loss: 3.3651,  X1 loss: 3.3458   X2 loss: 3.3843\n","====== Epoch: 260\n","====> Validation loss: 3.3861,  X1 loss: 3.3680   X2 loss: 3.4042\n","====== Epoch: 261\n","====> Validation loss: 3.3622,  X1 loss: 3.3414   X2 loss: 3.3829\n","====== Epoch: 262\n","====> Validation loss: 3.3322,  X1 loss: 3.3149   X2 loss: 3.3495\n","====== Epoch: 263\n","====> Validation loss: 3.3709,  X1 loss: 3.3549   X2 loss: 3.3869\n","====== Epoch: 264\n","====> Validation loss: 3.3480,  X1 loss: 3.3251   X2 loss: 3.3708\n","====== Epoch: 265\n","====> Validation loss: 3.3284,  X1 loss: 3.3125   X2 loss: 3.3443\n","====== Epoch: 266\n","====> Validation loss: 3.3483,  X1 loss: 3.3315   X2 loss: 3.3650\n","====== Epoch: 267\n","====> Validation loss: 3.3079,  X1 loss: 3.2853   X2 loss: 3.3304\n","====== Epoch: 268\n","====> Validation loss: 3.3430,  X1 loss: 3.3313   X2 loss: 3.3546\n","====== Epoch: 269\n","====> Validation loss: 3.3526,  X1 loss: 3.3391   X2 loss: 3.3661\n","====== Epoch: 270\n","====> Validation loss: 3.3682,  X1 loss: 3.3445   X2 loss: 3.3920\n","====== Epoch: 271\n","====> Validation loss: 3.3452,  X1 loss: 3.3285   X2 loss: 3.3619\n","====== Epoch: 272\n","====> Validation loss: 3.3414,  X1 loss: 3.3183   X2 loss: 3.3644\n","====== Epoch: 273\n","====> Validation loss: 3.3378,  X1 loss: 3.3163   X2 loss: 3.3594\n","====== Epoch: 274\n","====> Validation loss: 3.3145,  X1 loss: 3.2961   X2 loss: 3.3328\n","====== Epoch: 275\n","====> Validation loss: 3.3169,  X1 loss: 3.3031   X2 loss: 3.3306\n","====== Epoch: 276\n","====> Validation loss: 3.3337,  X1 loss: 3.3234   X2 loss: 3.3441\n","====== Epoch: 277\n","====> Validation loss: 3.3395,  X1 loss: 3.3202   X2 loss: 3.3589\n","====== Epoch: 278\n","====> Validation loss: 3.3515,  X1 loss: 3.3314   X2 loss: 3.3715\n","====== Epoch: 279\n","====> Validation loss: 3.3526,  X1 loss: 3.3363   X2 loss: 3.3689\n","====== Epoch: 280\n","====> Validation loss: 3.3264,  X1 loss: 3.3052   X2 loss: 3.3477\n","====== Epoch: 281\n","====> Validation loss: 3.3445,  X1 loss: 3.3273   X2 loss: 3.3617\n","====== Epoch: 282\n","====> Validation loss: 3.3587,  X1 loss: 3.3431   X2 loss: 3.3744\n","====== Epoch: 283\n","====> Validation loss: 3.3225,  X1 loss: 3.3086   X2 loss: 3.3365\n","====== Epoch: 284\n","====> Validation loss: 3.3286,  X1 loss: 3.3124   X2 loss: 3.3449\n","====== Epoch: 285\n","====> Validation loss: 3.3493,  X1 loss: 3.3337   X2 loss: 3.3649\n","====== Epoch: 286\n","====> Validation loss: 3.3554,  X1 loss: 3.3323   X2 loss: 3.3785\n","====== Epoch: 287\n","====> Validation loss: 3.3368,  X1 loss: 3.3218   X2 loss: 3.3518\n","====== Epoch: 288\n","====> Validation loss: 3.3340,  X1 loss: 3.3120   X2 loss: 3.3560\n","====== Epoch: 289\n","====> Validation loss: 3.3432,  X1 loss: 3.3215   X2 loss: 3.3648\n","====== Epoch: 290\n","====> Validation loss: 3.3331,  X1 loss: 3.3194   X2 loss: 3.3469\n","====== Epoch: 291\n","====> Validation loss: 3.3401,  X1 loss: 3.3225   X2 loss: 3.3577\n","====== Epoch: 292\n","====> Validation loss: 3.3452,  X1 loss: 3.3358   X2 loss: 3.3546\n","====== Epoch: 293\n","====> Validation loss: 3.3209,  X1 loss: 3.2982   X2 loss: 3.3436\n","====== Epoch: 294\n","====> Validation loss: 3.3289,  X1 loss: 3.3095   X2 loss: 3.3483\n","====== Epoch: 295\n","====> Validation loss: 3.3119,  X1 loss: 3.2906   X2 loss: 3.3332\n","====== Epoch: 296\n","====> Validation loss: 3.3759,  X1 loss: 3.3550   X2 loss: 3.3968\n","====== Epoch: 297\n","====> Validation loss: 3.3322,  X1 loss: 3.3189   X2 loss: 3.3456\n","====== Epoch: 298\n","====> Validation loss: 3.3826,  X1 loss: 3.3551   X2 loss: 3.4101\n","====== Epoch: 299\n","====> Validation loss: 3.3237,  X1 loss: 3.2987   X2 loss: 3.3487\n","====== Epoch: 300\n","====> Validation loss: 3.3766,  X1 loss: 3.3560   X2 loss: 3.3971\n","====== Epoch: 301\n","====> Validation loss: 3.3289,  X1 loss: 3.3074   X2 loss: 3.3504\n","====== Epoch: 302\n","====> Validation loss: 3.3360,  X1 loss: 3.3194   X2 loss: 3.3526\n","====== Epoch: 303\n","====> Validation loss: 3.3863,  X1 loss: 3.3553   X2 loss: 3.4174\n","====== Epoch: 304\n","====> Validation loss: 3.3262,  X1 loss: 3.3068   X2 loss: 3.3456\n","====== Epoch: 305\n","====> Validation loss: 3.3365,  X1 loss: 3.3202   X2 loss: 3.3528\n","====== Epoch: 306\n","====> Validation loss: 3.3364,  X1 loss: 3.3125   X2 loss: 3.3603\n","====== Epoch: 307\n","====> Validation loss: 3.3321,  X1 loss: 3.3118   X2 loss: 3.3523\n","====== Epoch: 308\n","====> Validation loss: 3.3379,  X1 loss: 3.3239   X2 loss: 3.3518\n","====== Epoch: 309\n","====> Validation loss: 3.3328,  X1 loss: 3.3137   X2 loss: 3.3519\n","====== Epoch: 310\n","====> Validation loss: 3.3185,  X1 loss: 3.3000   X2 loss: 3.3369\n","====== Epoch: 311\n","====> Validation loss: 3.3405,  X1 loss: 3.3306   X2 loss: 3.3503\n","====== Epoch: 312\n","====> Validation loss: 3.3363,  X1 loss: 3.3155   X2 loss: 3.3571\n","====== Epoch: 313\n","====> Validation loss: 3.3279,  X1 loss: 3.3096   X2 loss: 3.3462\n","====== Epoch: 314\n","====> Validation loss: 3.3203,  X1 loss: 3.3032   X2 loss: 3.3374\n","====== Epoch: 315\n","====> Validation loss: 3.3602,  X1 loss: 3.3390   X2 loss: 3.3814\n","====== Epoch: 316\n","====> Validation loss: 3.3197,  X1 loss: 3.2973   X2 loss: 3.3422\n","====== Epoch: 317\n","====> Validation loss: 3.3538,  X1 loss: 3.3379   X2 loss: 3.3696\n","====== Epoch: 318\n","====> Validation loss: 3.3181,  X1 loss: 3.2972   X2 loss: 3.3390\n","====== Epoch: 319\n","====> Validation loss: 3.3510,  X1 loss: 3.3288   X2 loss: 3.3732\n","====== Epoch: 320\n","====> Validation loss: 3.3523,  X1 loss: 3.3336   X2 loss: 3.3711\n","====== Epoch: 321\n","====> Validation loss: 3.3532,  X1 loss: 3.3330   X2 loss: 3.3735\n","====== Epoch: 322\n","====> Validation loss: 3.3405,  X1 loss: 3.3278   X2 loss: 3.3531\n","====== Epoch: 323\n","====> Validation loss: 3.3408,  X1 loss: 3.3211   X2 loss: 3.3605\n","====== Epoch: 324\n","====> Validation loss: 3.3269,  X1 loss: 3.3095   X2 loss: 3.3444\n","====== Epoch: 325\n","====> Validation loss: 3.3222,  X1 loss: 3.3094   X2 loss: 3.3349\n","====== Epoch: 326\n","====> Validation loss: 3.3369,  X1 loss: 3.3142   X2 loss: 3.3596\n","====== Epoch: 327\n","====> Validation loss: 3.3816,  X1 loss: 3.3580   X2 loss: 3.4052\n","====== Epoch: 328\n","====> Validation loss: 3.3555,  X1 loss: 3.3326   X2 loss: 3.3784\n","====== Epoch: 329\n","====> Validation loss: 3.3501,  X1 loss: 3.3347   X2 loss: 3.3655\n","====== Epoch: 330\n","====> Validation loss: 3.3181,  X1 loss: 3.2964   X2 loss: 3.3398\n","====== Epoch: 331\n","====> Validation loss: 3.3222,  X1 loss: 3.3077   X2 loss: 3.3368\n","====== Epoch: 332\n","====> Validation loss: 3.3206,  X1 loss: 3.3031   X2 loss: 3.3380\n","====== Epoch: 333\n","====> Validation loss: 3.3635,  X1 loss: 3.3452   X2 loss: 3.3819\n","====== Epoch: 334\n","====> Validation loss: 3.3516,  X1 loss: 3.3322   X2 loss: 3.3711\n","====== Epoch: 335\n","====> Validation loss: 3.3313,  X1 loss: 3.3098   X2 loss: 3.3529\n","====== Epoch: 336\n","====> Validation loss: 3.3135,  X1 loss: 3.2841   X2 loss: 3.3429\n","====== Epoch: 337\n","====> Validation loss: 3.3315,  X1 loss: 3.3097   X2 loss: 3.3533\n","====== Epoch: 338\n","====> Validation loss: 3.3414,  X1 loss: 3.3298   X2 loss: 3.3530\n","====== Epoch: 339\n","====> Validation loss: 3.3527,  X1 loss: 3.3297   X2 loss: 3.3757\n","====== Epoch: 340\n","====> Validation loss: 3.3336,  X1 loss: 3.3174   X2 loss: 3.3498\n","====== Epoch: 341\n","====> Validation loss: 3.3288,  X1 loss: 3.3081   X2 loss: 3.3494\n","====== Epoch: 342\n","====> Validation loss: 3.3376,  X1 loss: 3.3255   X2 loss: 3.3496\n","====== Epoch: 343\n","====> Validation loss: 3.3444,  X1 loss: 3.3220   X2 loss: 3.3669\n","====== Epoch: 344\n","====> Validation loss: 3.3408,  X1 loss: 3.3190   X2 loss: 3.3627\n","====== Epoch: 345\n","====> Validation loss: 3.3034,  X1 loss: 3.2929   X2 loss: 3.3139\n","====== Epoch: 346\n","====> Validation loss: 3.3354,  X1 loss: 3.3240   X2 loss: 3.3468\n","====== Epoch: 347\n","====> Validation loss: 3.3127,  X1 loss: 3.2996   X2 loss: 3.3258\n","====== Epoch: 348\n","====> Validation loss: 3.3544,  X1 loss: 3.3395   X2 loss: 3.3693\n","====== Epoch: 349\n","====> Validation loss: 3.3356,  X1 loss: 3.3156   X2 loss: 3.3556\n","====== Epoch: 350\n","====> Validation loss: 3.3305,  X1 loss: 3.3151   X2 loss: 3.3458\n","====== Epoch: 351\n","====> Validation loss: 3.3663,  X1 loss: 3.3508   X2 loss: 3.3818\n","====== Epoch: 352\n","====> Validation loss: 3.3416,  X1 loss: 3.3170   X2 loss: 3.3662\n","====== Epoch: 353\n","====> Validation loss: 3.3407,  X1 loss: 3.3266   X2 loss: 3.3549\n","====== Epoch: 354\n","====> Validation loss: 3.3375,  X1 loss: 3.3191   X2 loss: 3.3558\n","====== Epoch: 355\n","====> Validation loss: 3.3468,  X1 loss: 3.3266   X2 loss: 3.3669\n","====== Epoch: 356\n","====> Validation loss: 3.3251,  X1 loss: 3.3095   X2 loss: 3.3407\n","====== Epoch: 357\n","====> Validation loss: 3.3239,  X1 loss: 3.3063   X2 loss: 3.3414\n","====== Epoch: 358\n","====> Validation loss: 3.3329,  X1 loss: 3.3123   X2 loss: 3.3535\n","====== Epoch: 359\n","====> Validation loss: 3.3438,  X1 loss: 3.3251   X2 loss: 3.3626\n","====== Epoch: 360\n","====> Validation loss: 3.3352,  X1 loss: 3.3116   X2 loss: 3.3589\n","====== Epoch: 361\n","====> Validation loss: 3.3337,  X1 loss: 3.3161   X2 loss: 3.3512\n","====== Epoch: 362\n","====> Validation loss: 3.3262,  X1 loss: 3.3074   X2 loss: 3.3450\n","====== Epoch: 363\n","====> Validation loss: 3.3347,  X1 loss: 3.3158   X2 loss: 3.3536\n","====== Epoch: 364\n","====> Validation loss: 3.3478,  X1 loss: 3.3311   X2 loss: 3.3645\n","====== Epoch: 365\n","====> Validation loss: 3.3573,  X1 loss: 3.3383   X2 loss: 3.3764\n","====== Epoch: 366\n","====> Validation loss: 3.3702,  X1 loss: 3.3519   X2 loss: 3.3885\n","====== Epoch: 367\n","====> Validation loss: 3.3461,  X1 loss: 3.3229   X2 loss: 3.3692\n","====== Epoch: 368\n","====> Validation loss: 3.3354,  X1 loss: 3.3192   X2 loss: 3.3517\n","====== Epoch: 369\n","====> Validation loss: 3.3264,  X1 loss: 3.3084   X2 loss: 3.3444\n","====== Epoch: 370\n","====> Validation loss: 3.3195,  X1 loss: 3.3000   X2 loss: 3.3390\n","====== Epoch: 371\n","====> Validation loss: 3.3145,  X1 loss: 3.3007   X2 loss: 3.3282\n","====== Epoch: 372\n","====> Validation loss: 3.3314,  X1 loss: 3.3137   X2 loss: 3.3491\n","====== Epoch: 373\n","====> Validation loss: 3.3665,  X1 loss: 3.3431   X2 loss: 3.3898\n","====== Epoch: 374\n","====> Validation loss: 3.3131,  X1 loss: 3.2923   X2 loss: 3.3340\n","====== Epoch: 375\n","====> Validation loss: 3.3361,  X1 loss: 3.3133   X2 loss: 3.3589\n","====== Epoch: 376\n","====> Validation loss: 3.3142,  X1 loss: 3.2949   X2 loss: 3.3335\n","====== Epoch: 377\n","====> Validation loss: 3.3429,  X1 loss: 3.3165   X2 loss: 3.3694\n","====== Epoch: 378\n","====> Validation loss: 3.3018,  X1 loss: 3.2904   X2 loss: 3.3132\n","====== Epoch: 379\n","====> Validation loss: 3.3172,  X1 loss: 3.2991   X2 loss: 3.3353\n","====== Epoch: 380\n","====> Validation loss: 3.3177,  X1 loss: 3.3110   X2 loss: 3.3244\n","====== Epoch: 381\n","====> Validation loss: 3.3347,  X1 loss: 3.3128   X2 loss: 3.3566\n","====== Epoch: 382\n","====> Validation loss: 3.3336,  X1 loss: 3.3208   X2 loss: 3.3464\n","====== Epoch: 383\n","====> Validation loss: 3.3412,  X1 loss: 3.3176   X2 loss: 3.3648\n","====== Epoch: 384\n","====> Validation loss: 3.3323,  X1 loss: 3.3155   X2 loss: 3.3490\n","====== Epoch: 385\n","====> Validation loss: 3.3198,  X1 loss: 3.3009   X2 loss: 3.3388\n","====== Epoch: 386\n","====> Validation loss: 3.3347,  X1 loss: 3.3198   X2 loss: 3.3497\n","====== Epoch: 387\n","====> Validation loss: 3.3309,  X1 loss: 3.3106   X2 loss: 3.3512\n","====== Epoch: 388\n","====> Validation loss: 3.3644,  X1 loss: 3.3329   X2 loss: 3.3959\n","====== Epoch: 389\n","====> Validation loss: 3.3500,  X1 loss: 3.3318   X2 loss: 3.3682\n","====== Epoch: 390\n","====> Validation loss: 3.3604,  X1 loss: 3.3361   X2 loss: 3.3846\n","====== Epoch: 391\n","====> Validation loss: 3.3224,  X1 loss: 3.2996   X2 loss: 3.3451\n","====== Epoch: 392\n","====> Validation loss: 3.3431,  X1 loss: 3.3213   X2 loss: 3.3648\n","====== Epoch: 393\n","====> Validation loss: 3.3302,  X1 loss: 3.3165   X2 loss: 3.3439\n","====== Epoch: 394\n","====> Validation loss: 3.3819,  X1 loss: 3.3676   X2 loss: 3.3962\n","====== Epoch: 395\n","====> Validation loss: 3.3340,  X1 loss: 3.3153   X2 loss: 3.3527\n","====== Epoch: 396\n","====> Validation loss: 3.3213,  X1 loss: 3.3053   X2 loss: 3.3373\n","====== Epoch: 397\n","====> Validation loss: 3.3304,  X1 loss: 3.3082   X2 loss: 3.3525\n","====== Epoch: 398\n","====> Validation loss: 3.3447,  X1 loss: 3.3271   X2 loss: 3.3622\n","====== Epoch: 399\n","====> Validation loss: 3.3255,  X1 loss: 3.3117   X2 loss: 3.3394\n"]}],"source":["\n","\n","\n","\n","\n","\n","# Read the command-line argument passed to the interpreter when invoking the script\n","lr = 0.001#sys.argv[1]\n","batch_size = 64# sys.argv[2]\n","\n","\n","# Read data\n","subj_ids = list(range(1, 20))\n","fs = 128\n","window_size = int(5 * fs)\n","stride_size_train, stride_size_val, stride_size_test = int(2.5 * fs), int(5 * fs), int(5 * fs)\n","batch_size = int(batch_size)\n","lr = lr\n","\n","n_channs = 129 # 128 for eeg, 1 for env\n","print('-------------------------------------')\n","print(f'window_size: {window_size}  stride_size_test: {stride_size_test}')\n","\n","dataset_name = ['rochester_data', 'natural_speech']\n","outputs_path = f'../outputs/'\n","data_path = os.path.join(outputs_path, dataset_name[0], dataset_name[1])\n","after_ica_path = os.path.join(data_path, 'after_ica_raw')\n","print(f'data_path: {data_path}')\n","\n","\n","X = load_data(subj_ids, after_ica_path, window_size, \n","              stride_size_train, stride_size_val, stride_size_test, n_channs)\n","\n","\n","# Create dataloaders\n","class MyDataset(Dataset):\n","    def __init__(self, eeg, env):\n","        self.eeg = eeg\n","        self.env = env\n","    \n","    def __getitem__(self, index):\n","        return self.eeg[index], self.env[index]\n","    \n","    def __len__(self):\n","        return len(self.eeg)\n","    \n","\n","dataset_train = MyDataset(X['eegs_train'], X['envs_train'])\n","dl_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","dl_val = DataLoader(MyDataset(X[\"eegs_val\"], X[\"envs_val\"]), \n","                    batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","\n","\n","# Create model\n","eeg_encoder = EEGEncoder()\n","env_encoder = EnvelopeEncoder()\n","model = CLEE(eeg_encoder, env_encoder)\n","model.to(device)\n","\n","# Train model\n","models_dict = {f'lr_{lr}_bs_{batch_size}': model}\n","lossi = []\n","udri = [] # update / data ratio \n","ud = []\n","\n","\n","\n","for name, model in models_dict.items():\n","\n","    # Reset for the new model in the loop\n","    print(f\"+--------------New model: {name}----------------------+\")\n","    writer = SummaryWriter(log_dir=f\"runs/{name}_{time.strftime('%Y%m%d_%H%M%S')}\")\n","    model.to(device)\n","    optimizer = optim.NAdam(model.parameters(), lr=lr)\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.7)\n","    cnt = 0\n","    loss_batches = []\n","\n","\n","    for epoch in range(1, 400):\n","\n","        print(f\"====== Epoch: {epoch}\")\n","\n","        model.train()\n","        for ix_batch, (Xb_eeg, Xb_env) in enumerate(dl_train):\n","\n","            # send to device\n","            Xb_eeg = Xb_eeg.to(device)\n","            Xb_env = Xb_env.to(device)\n","\n","            # Zero out gradients\n","            optimizer.zero_grad()\n","\n","            # forward pass\n","            eeg_features, env_features, logit_scale = model(Xb_eeg, Xb_env) \n","\n","\n","            # normalize features\n","            eeg_features_n = eeg_features / eeg_features.norm(dim=1, keepdim=True)\n","            env_features_n = env_features / env_features.norm(dim=1, keepdim=True)\n","\n","            # logits\n","            logits_per_eeg = logit_scale * eeg_features_n @ env_features_n.t()\n","            logits_per_env = logits_per_eeg.t()\n","\n","            #loss function\n","            labels = torch.arange(batch_size).to(device)\n","            loss_eeg = F.cross_entropy(logits_per_eeg, labels)\n","            loss_env = F.cross_entropy(logits_per_env, labels)\n","            loss   = (loss_eeg + loss_env)/2\n","\n","            # backward pass\n","            loss.backward()\n","            optimizer.step()\n","\n","            loss_batches.append(loss.item())\n","            cnt += 1\n","\n","            with torch.no_grad():\n","                #ud = {f\"p{ix}\":(lr*p.grad.std() / p.data.std()).log10().item() for ix, p in enumerate(model.parameters()) if p.ndim==4 }\n","                #writer.add_scalars('UpdateOData/ud', ud, cnt)\n","                writer.add_scalar('Loss/train_batch', loss.item(), cnt)\n","\n","            # normalize weights\n","            with torch.no_grad():\n","                model.eeg_encoder.normalize_weights()\n","            \n","            #break   \n","\n","        loss_epoch = loss_batches[-(ix_batch + 1):]  # mean loss across batches\n","        loss_epoch = sum(loss_epoch) / len(loss_epoch)\n","        writer.add_scalar('Loss/train_epoch', loss_epoch, epoch)\n","        #for pname, p in model.named_parameters():\n","        #writer.add_histogram(f'Params/{pname}', p, epoch)\n","        #writer.add_histogram(f'Grads/{pname}', p.grad, epoch)\n","\n","        loss_val, *_ = eval_model_cl(dl_val, model, device=device)\n","        writer.add_scalar('Loss/val_epoch', loss_val, epoch)\n","\n","        \n","\n","        model.train()\n","\n","        # Update learning rate based on epoch\n","        scheduler.step()\n","            \n","    #break   \n","\n","\n","\n","\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.5"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"colab":{"provenance":[],"machine_shape":"hm"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"5d23a32b5d144a4eb1b6ac8d70e85626":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_c65664b7079942faaa4b463ee45797ac","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">     <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">7.6/7.6 MB</span> <span style=\"color: #800000; text-decoration-color: #800000\">71.5 MB/s</span> eta <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span>\n</pre>\n"},"metadata":{}}]}},"c65664b7079942faaa4b463ee45797ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}