{"cells":[{"cell_type":"markdown","metadata":{"id":"VhCK252zNjUG"},"source":["## COLAB TOOLS"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2390,"status":"ok","timestamp":1677754861799,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"v-pxnK4OaI-b","outputId":"a106ff2a-848e-4b30-c3f1-e554cfd79fa3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1677754861800,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"ZEopbadxbJH0","outputId":"798c2bce-ba12-43e2-fb36-c6a8580c177d"},"outputs":[{"output_type":"stream","name":"stdout","text":["['train_cl_eeg2speech_rochester_v3_test_gridsearch.ipynb', '.git', '.DS_Store', '.gitignore', 'EEG', 'LICENSE', 'train_cl_eeg2speech_rochester_v1.ipynb', 'train_cl_eeg2speech_rochester_v2.ipynb', '.ipynb_checkpoints', 'train_cl_eeg2speech_rochester_v3_test_old.ipynb', 'runs', 'train_cl_eeg2speech_rochester_v3_test.ipynb', 'train_cl_eeg2speech_rochester_v4_gridseaerch.ipynb', 'train_cl_eeg2speech_2.ipynb', 'train_cl_eeg2speech_rochester_subj_2.ipynb', 'README.md', 'train_eeg2speech_rochester.ipynb', 'train_cl_eeg2speech_rochester_v3.ipynb']\n"]}],"source":["\n","import os\n","import sys\n","\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"Colab Notebooks/prj_neuroread_analysis/neuroread/\"\n","GOOGLE_DRIVE_PATH = os.path.join(\"/content\", \"drive\", \"MyDrive\", GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","\n","# Add to sys so we can import .py files.\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","os.chdir(GOOGLE_DRIVE_PATH)\n","\n","# Install unavailable packages\n","import pip\n","def import_or_install(package):\n","    try:\n","        __import__(package)\n","    except ImportError:\n","        pip.main(['install', package])\n","\n","import_or_install(\"mne\")\n"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1677754861800,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"M0LuZowEbY29","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ad0c493c-a1a3-43a6-8ccd-8294a0dbc500"},"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1339,"status":"ok","timestamp":1677754863135,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"HTqIrJcOaQLu","outputId":"48242375-e84a-4a4d-c9ba-95cc5a3d9048"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 89.6 gigabytes of available RAM\n","\n","Thu Mar  2 11:01:01 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    50W / 400W |   2681MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n"," print('Not connected to a GPU')\n","else:\n"," print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"aXEXbz7ENjUM"},"source":["## Main code"]},{"cell_type":"code","source":["#%reset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOmC9QbE-kZz","executionInfo":{"status":"ok","timestamp":1677754793597,"user_tz":-60,"elapsed":7880,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"}},"outputId":"ade8b519-73f0-4e8a-ef5b-55e3091daf8e"},"execution_count":24,"outputs":[{"name":"stdout","output_type":"stream","text":["Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"]}]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":193,"status":"ok","timestamp":1677754870956,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"gGggzCoKZQeu","outputId":"a246fbff-308e-48bf-d82b-79086c7fdc45"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["import os, sys, glob\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import numpy as np\n","\n","import mne\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import time\n","\n","from torchsummary import summary\n","from torch.utils.tensorboard import SummaryWriter\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":1353,"status":"ok","timestamp":1677754872637,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"GYgZe_3OQniG"},"outputs":[],"source":["def eval_model_cl(dl, model, device=torch.device('cpu'), verbose=True):\n","    \"\"\" \n","    This function calculates the loss on data, setting backward gradients and batchnorm\n","    off. This function is written for contrasting learning where the model takes in two\n","    inputs.\n","\n","    Args:\n","\n","    Returns:\n","      loss_test: Mean loss of all test samples (scalar)\n","\n","    \"\"\"\n","    losses, losses_X1, losses_X2 = [], [], []\n","    model.to(device)  # inplace for model\n","    # Set the model in evaluation mode\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for idx_batch, (X1b, X2b) in enumerate(dl):\n","\n","            X1b = X1b.to(device)\n","            X2b = X2b.to(device)\n","\n","            X1b_features, X2b_features, logit_sc = model(X1b, X2b)\n","\n","            # Normalize features\n","            X1b_f_n = X1b_features / X1b_features.norm(dim=1, keepdim=True)\n","            X2b_f_n = X2b_features / X2b_features.norm(dim=1, keepdim=True)\n","\n","            logits_per_X1 = logit_sc * X1b_f_n @ X2b_f_n.t()\n","            logits_per_X2 = logits_per_X1.t()\n","\n","            # Number of labels equals to the 1st dimension of X1b\n","            labels = torch.arange(X1b.shape[0], device=device)\n","\n","            # Batch Loss \n","            loss_X1 = F.cross_entropy(logits_per_X1, labels)\n","            loss_X2 = F.cross_entropy(logits_per_X2, labels)\n","            loss_batch   = (loss_X1 + loss_X2) / 2\n","            losses.append(loss_batch.item())\n","            losses_X1.append(loss_X1.item())\n","            losses_X2.append(loss_X2.item())\n","\n","        # Epoch loss (mean of batch losses)\n","        loss  = sum(losses) / len(losses)\n","        loss_X1 = sum(losses_X1) / len(losses_X1)\n","        loss_X2 = sum(losses_X2) / len(losses_X2)\n","\n","        if verbose:\n","          print(f\"====> Validation loss: {loss:.4f},  X1 loss: {loss_X1:.4f}   X2 loss: {loss_X2:.4f}\")\n","\n","        return loss, loss_X1, loss_X2\n"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677754872637,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"EaAsZ-SLZQey"},"outputs":[],"source":["def unfold_raw(raw, window_size=None, stride=None):\n","    \"\"\"\n","    This function unfolds raw MNE object into a list of raw objects\n","    Args:\n","        raw: a raw MNE object cropped by rejecting bad segments.\n","    Returns:\n","        raw_unfolded: a raw MNE object unfolded by applying a sliding window.\n","    \"\"\"\n","    if window_size is None:\n","        window_size = int(5 * raw.info['sfreq'])\n","    if stride is None:\n","        stride = window_size\n","    nchans = len(raw.ch_names)\n","    sig = torch.tensor(raw.get_data(), dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n","    sig_unf = F.unfold(sig, (nchans, window_size), stride=stride , padding=0)\n","    sig_unf = sig_unf.permute(0, 2, 1).reshape(-1, sig_unf.shape[-1], nchans, window_size)\n","    return sig_unf"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677754872637,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"1cf9EoF3ZQey"},"outputs":[],"source":["def rm_repeated_annotations(raw):\n","    \"\"\"This functions taskes in raw MNE obejct and removes repeated annotations\"\"\"\n","    annots = raw.annotations.copy()\n","    annots_drop = []\n","    for k in annots:\n","        annots_drop.extend([k for kk in annots if (k['onset'] > kk['onset']) and (k['onset']+k['duration'] < kk['onset']+kk['duration']) ])\n","\n","    annots_updated = [i for i in annots if i not in annots_drop]\n","    onsets = [i['onset'] for i in annots_updated]\n","    durations = [i['duration'] for i in annots_updated]\n","    descriptions = [i['description'] for i in annots_updated]\n","    print('Initial num of annots: %d  Num of removed annots: %d  Num of retained annots:  %d' % (len(annots), len(annots_drop), len(annots_updated)))\n","    print(f' New annots: {annots_updated}')\n","    raw.set_annotations(mne.Annotations(onsets, durations, descriptions) ) \n","    return raw"]},{"cell_type":"markdown","metadata":{"id":"q4sGJAdFZQez"},"source":["## Read Data"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677754872638,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"KdQFfHcJZQe0","outputId":"488bc9f0-3c71-497f-8f3f-fa54ff04922b"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------------------------------------\n","window_size: 640  stride_size_test: 640\n","data_path: ../outputs/rochester_data/natural_speech\n"]}],"source":["subj_ids = list(range(1, 14))\n","fs = 128\n","window_size = int(5 * fs)\n","stride_size_train, stride_size_val, stride_size_test = int(2.5 * fs), int(5 * fs), int(5 * fs)\n","n_channs = 129 # 128 for eeg, 1 for env\n","batch_size = int(32)\n","print('-------------------------------------')\n","print(f'window_size: {window_size}  stride_size_test: {stride_size_test}')\n","\n","dataset_name = ['rochester_data', 'natural_speech']\n","outputs_path = f'../outputs/'\n","data_path = os.path.join(outputs_path, dataset_name[0], dataset_name[1])\n","after_ica_path = os.path.join(data_path, 'after_ica_raw')\n","print(f'data_path: {data_path}')"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":164526,"status":"ok","timestamp":1677755037158,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"fIhJi5IxZQe1","outputId":"f13613f5-41e1-414a-aa14-3020e1f0dd37"},"outputs":[{"output_type":"stream","name":"stdout","text":["Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_1_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 48  Num of removed annots: 19  Num of retained annots:  29\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.559097), ('duration', 2.240447998046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.084473), ('duration', 2.24041748046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.212158), ('duration', 2.0118408203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.890503), ('duration', 2.67486572265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 899.02771), ('duration', 2.05755615234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 983.746643), ('duration', 6.58416748046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1051.039551), ('duration', 1.8746337890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1100.719482), ('duration', 6.4012451171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1265.987061), ('duration', 3.269287109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.989502), ('duration', 2.080322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1611.904297), ('duration', 11.796630859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.480591), ('duration', 3.81787109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1977.884644), ('duration', 8.5731201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2058.135986), ('duration', 5.052490234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2161.450928), ('duration', 3.2236328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.70874), ('duration', 1.8291015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.632324), ('duration', 5.578369140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2656.933838), ('duration', 3.246337890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2699.549561), ('duration', 15.7060546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2892.681641), ('duration', 3.497802734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2977.071045), ('duration', 1.64599609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3079.503906), ('duration', 8.321533203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3220.774658), ('duration', 3.017822265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3257.32251), ('duration', 10.927978515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3327.002441), ('duration', 6.584228515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3438.776123), ('duration', 5.806884765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3480.157471), ('duration', 12.139404296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3607.381592), ('duration', 10.49365234375), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 26  N val: 1  N test: 1\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_2_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 65  Num of removed annots: 19  Num of retained annots:  46\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 177.009033), ('duration', 4.4808807373046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 233.547455), ('duration', 3.1549072265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 256.64325), ('duration', 4.549468994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.877777), ('duration', 1.554595947265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 419.798157), ('duration', 4.18365478515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 521.238403), ('duration', 3.72650146484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 536.986145), ('duration', 8.36737060546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 591.58136), ('duration', 12.36810302734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 684.541626), ('duration', 37.07598876953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 731.651611), ('duration', 0.9830322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 760.453308), ('duration', 5.80682373046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 895.355164), ('duration', 14.21990966796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 955.299988), ('duration', 3.9779052734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1010.325623), ('duration', 5.5782470703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1047.856567), ('duration', 3.0177001953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.390625), ('duration', 4.892333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.681152), ('duration', 8.984619140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1304.783569), ('duration', 3.2464599609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1385.044556), ('duration', 3.749267578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.464355), ('duration', 2.171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.947266), ('duration', 13.3740234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1636.351562), ('duration', 1.600341796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1650.508545), ('duration', 8.5731201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1683.526245), ('duration', 6.5384521484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1726.90979), ('duration', 6.2640380859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1807.079224), ('duration', 13.076904296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.602295), ('duration', 1.348876953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1991.061035), ('duration', 2.126220703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2049.411133), ('duration', 4.503662109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2136.050537), ('duration', 4.732421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.68042), ('duration', 11.659423828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2234.577881), ('duration', 7.315673828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.926758), ('duration', 14.63134765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.343262), ('duration', 9.076171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2546.635498), ('duration', 3.177734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.869873), ('duration', 15.68310546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.512939), ('duration', 8.481689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3081.322021), ('duration', 2.468994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3087.928955), ('duration', 6.835693359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3116.119141), ('duration', 3.886474609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3257.709961), ('duration', 6.652587890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3280.65918), ('duration', 5.71533203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3440.005615), ('duration', 0.914306640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3452.968018), ('duration', 7.29296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3604.318115), ('duration', 3.817138671875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 68  N val: 2  N test: 2\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_3_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 47  Num of removed annots: 19  Num of retained annots:  28\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 43.135948), ('duration', 4.115089416503906), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 121.796593), ('duration', 5.6010894775390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.748077), ('duration', 1.760345458984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 275.317291), ('duration', 2.994842529296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.205322), ('duration', 2.126129150390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.65863), ('duration', 1.89752197265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.599854), ('duration', 2.12615966796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.988525), ('duration', 1.6231689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1033.410278), ('duration', 0.9830322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.293579), ('duration', 1.7603759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.313721), ('duration', 3.56640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1307.502563), ('duration', 0.86865234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.074097), ('duration', 2.4461669921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1583.876953), ('duration', 0.3658447265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.867554), ('duration', 1.9432373046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.839478), ('duration', 1.9661865234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.358643), ('duration', 2.1947021484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.061523), ('duration', 2.14892578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.888916), ('duration', 0.8916015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.831299), ('duration', 2.92626953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.159668), ('duration', 2.01171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2790.049561), ('duration', 9.510498046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.086426), ('duration', 2.400390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3081.215576), ('duration', 1.874755859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.645996), ('duration', 2.14892578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.272217), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3525.888916), ('duration', 1.87451171875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 93  N val: 3  N test: 3\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_4_after_ica_raw.fif...\n","    Range : 0 ... 464394 =      0.000 ...  3628.078 secs\n","Ready.\n","Reading 0 ... 464394  =      0.000 ...  3628.078 secs...\n","Initial num of annots: 41  Num of removed annots: 19  Num of retained annots:  22\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.316391), ('duration', 2.4461822509765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.619507), ('duration', 1.074493408203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.230835), ('duration', 1.851806640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.968323), ('duration', 4.89239501953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.236755), ('duration', 2.56048583984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1100.372314), ('duration', 2.5833740234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1265.114136), ('duration', 4.6181640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.281372), ('duration', 1.874755859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.327759), ('duration', 1.783203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.417358), ('duration', 1.2344970703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1981.789795), ('duration', 2.720458984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2161.278076), ('duration', 4.8466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2344.500732), ('duration', 1.80615234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.130127), ('duration', 2.194580078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2706.033447), ('duration', 2.743408203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2876.088623), ('duration', 1.6689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2892.718506), ('duration', 0.822998046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3079.622803), ('duration', 2.217529296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.026855), ('duration', 6.172607421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3438.603516), ('duration', 0.822998046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3535.585693), ('duration', 2.720458984375), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 112  N val: 4  N test: 4\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_5_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 41  Num of removed annots: 19  Num of retained annots:  22\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 177.408173), ('duration', 0.270477294921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 358.121857), ('duration', 0.270477294921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.280273), ('duration', 1.9835205078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.369812), ('duration', 2.3441162109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 899.271362), ('duration', 1.3974609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.870972), ('duration', 0.4508056640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.272949), ('duration', 1.4425048828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.279663), ('duration', 1.126953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.049805), ('duration', 1.8707275390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1701.652954), ('duration', 0.96923828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.822144), ('duration', 2.434326171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.066284), ('duration', 2.186279296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2161.976074), ('duration', 1.983642578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.484619), ('duration', 1.870849609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2524.411133), ('duration', 0.541015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.077393), ('duration', 2.569580078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.742432), ('duration', 0.8564453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3081.496094), ('duration', 0.653564453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3229.895752), ('duration', 1.84814453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.698975), ('duration', 2.727294921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.993408), ('duration', 0.901611328125), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 131  N val: 5  N test: 5\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_6_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 58  Num of removed annots: 19  Num of retained annots:  39\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.775345), ('duration', 1.6688995361328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 282.102112), ('duration', 2.56048583984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.346893), ('duration', 2.263275146484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 523.917664), ('duration', 2.1260986328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 536.834473), ('duration', 2.56048583984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.924316), ('duration', 5.0753173828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 757.242065), ('duration', 2.65191650390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 837.127747), ('duration', 3.177734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 879.596802), ('duration', 2.5147705078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 897.584961), ('duration', 4.526611328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.219971), ('duration', 2.0574951171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1218.668945), ('duration', 2.4461669921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.177368), ('duration', 1.7603759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1405.632324), ('duration', 2.3089599609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.297607), ('duration', 1.8746337890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1469.58728), ('duration', 2.03466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1497.78125), ('duration', 2.4461669921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1554.397705), ('duration', 10.470703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1608.48999), ('duration', 8.39013671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1634.155762), ('duration', 2.468994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1747.676392), ('duration', 4.3209228515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1807.026855), ('duration', 1.6002197265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.125), ('duration', 2.7890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2036.889648), ('duration', 4.7322998046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2122.203125), ('duration', 2.03466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.363037), ('duration', 1.623291015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2253.597656), ('duration', 2.491943359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.462646), ('duration', 2.034912109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2487.927979), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2524.04541), ('duration', 1.92041015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2603.16333), ('duration', 1.8974609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2706.935303), ('duration', 2.743408203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.359375), ('duration', 2.0576171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.958984), ('duration', 1.783203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3111.987793), ('duration', 0.64013671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.530518), ('duration', 2.8349609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3403.469971), ('duration', 1.1201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.724609), ('duration', 1.028564453125), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 167  N val: 6  N test: 6\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_7_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 74  Num of removed annots: 18  Num of retained annots:  56\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.368912), ('duration', 2.6062164306640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 202.71106), ('duration', 3.5206756591796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 315.806854), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 356.574677), ('duration', 2.903411865234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 534.393311), ('duration', 6.35552978515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.769409), ('duration', 1.44024658203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 899.308594), ('duration', 2.5147705078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 981.924255), ('duration', 1.8289794921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 995.180115), ('duration', 2.53765869140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1054.425659), ('duration', 13.945556640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1091.636597), ('duration', 3.54345703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1100.598267), ('duration', 3.2235107421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1187.123291), ('duration', 1.851806640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.292847), ('duration', 1.2574462890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1323.053955), ('duration', 1.5089111328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.083496), ('duration', 1.8289794921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1504.320801), ('duration', 2.354736328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1536.858521), ('duration', 5.1666259765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.278198), ('duration', 1.9432373046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1668.210327), ('duration', 2.766357421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1713.217041), ('duration', 1.80615234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1729.60498), ('duration', 3.1319580078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1784.040039), ('duration', 8.756103515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1805.663208), ('duration', 3.7950439453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.498901), ('duration', 2.0574951171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2096.175781), ('duration', 2.37744140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2157.560791), ('duration', 10.72216796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2288.804688), ('duration', 3.955078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2330.930908), ('duration', 2.468994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.640381), ('duration', 1.600341796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2363.354248), ('duration', 2.080322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2398.324707), ('duration', 2.354736328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.527588), ('duration', 2.53759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2550.565186), ('duration', 6.149658203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2706.920654), ('duration', 2.857666015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.047607), ('duration', 2.26318359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2912.270264), ('duration', 3.2919921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2929.330566), ('duration', 3.08642578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2943.047607), ('duration', 4.09228515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2969.869873), ('duration', 3.497802734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2992.805664), ('duration', 3.246337890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3006.655762), ('duration', 2.743408203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.669922), ('duration', 3.04052734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3104.24585), ('duration', 2.171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3139.366943), ('duration', 1.463134765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3160.199219), ('duration', 6.67578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3224.72583), ('duration', 9.05322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.845459), ('duration', 2.6748046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3312.975098), ('duration', 3.132080078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3358.553223), ('duration', 2.8349609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3393.308594), ('duration', 2.080322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3432.110352), ('duration', 2.583251953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3440.40625), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3503.788574), ('duration', 3.360595703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3555.731934), ('duration', 7.33837890625), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 220  N val: 7  N test: 7\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_8_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 42  Num of removed annots: 19  Num of retained annots:  23\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.14798), ('duration', 2.926300048828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.06424), ('duration', 2.2633056640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 371.421326), ('duration', 5.235321044921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 536.955017), ('duration', 4.4808349609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.692444), ('duration', 2.37762451171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.715332), ('duration', 2.65191650390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.184326), ('duration', 2.19482421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.598633), ('duration', 2.743408203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.696045), ('duration', 5.6468505859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.613281), ('duration', 11.3165283203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.690186), ('duration', 2.53759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.835938), ('duration', 1.348876953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.807617), ('duration', 0.8916015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2344.188721), ('duration', 3.269287109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2377.503662), ('duration', 2.92626953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.80957), ('duration', 1.874755859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.339844), ('duration', 1.87451171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2716.461426), ('duration', 2.240478515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2888.094238), ('duration', 7.0185546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.641357), ('duration', 2.2861328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.550049), ('duration', 2.652099609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.231689), ('duration', 2.19482421875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 240  N val: 8  N test: 8\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_9_after_ica_raw.fif...\n","    Range : 0 ... 464396 =      0.000 ...  3628.094 secs\n","Ready.\n","Reading 0 ... 464396  =      0.000 ...  3628.094 secs...\n","Initial num of annots: 50  Num of removed annots: 19  Num of retained annots:  31\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 130.882126), ('duration', 1.5317230224609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 175.55928), ('duration', 3.543548583984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 264.037018), ('duration', 2.994873046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 356.953827), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.136719), ('duration', 2.60626220703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.279785), ('duration', 2.19476318359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 805.422119), ('duration', 2.03466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 863.707458), ('duration', 1.5089111328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.531311), ('duration', 2.1947021484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 942.221497), ('duration', 1.16595458984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1100.621216), ('duration', 2.103271484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.725952), ('duration', 1.2344970703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1361.294312), ('duration', 1.851806640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1436.863159), ('duration', 3.3377685546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1612.4375), ('duration', 5.2352294921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1627.293579), ('duration', 2.6519775390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1664.12915), ('duration', 145.87548828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.199341), ('duration', 14.970458984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2160.909668), ('duration', 2.720458984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2343.753906), ('duration', 3.955078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2376.438232), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2522.852783), ('duration', 2.08056640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2621.444824), ('duration', 2.2861328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2704.782715), ('duration', 5.006591796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2779.488281), ('duration', 3.4521484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2890.36084), ('duration', 4.572509765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3018.792969), ('duration', 2.2861328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3073.694824), ('duration', 8.207275390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3260.755127), ('duration', 1.966064453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3437.777588), ('duration', 2.468994140625), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 268  N val: 9  N test: 9\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_10_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 69  Num of removed annots: 18  Num of retained annots:  51\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 149.729568), ('duration', 2.286163330078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.793808), ('duration', 1.5088653564453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 211.101257), ('duration', 1.3259735107421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 304.370483), ('duration', 2.6748046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.593964), ('duration', 3.429229736328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 423.59317), ('duration', 4.526611328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 492.564392), ('duration', 6.309814453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.557739), ('duration', 1.6231689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 572.701599), ('duration', 2.994873046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 612.724426), ('duration', 2.5833740234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 719.066589), ('duration', 4.8466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 811.009827), ('duration', 2.1260986328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 880.173401), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 887.100464), ('duration', 2.21759033203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 900.03125), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1025.614502), ('duration', 2.81201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.146973), ('duration', 3.8636474609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1150.301147), ('duration', 2.14892578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1233.59314), ('duration', 1.7603759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.456787), ('duration', 3.0406494140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1362.038574), ('duration', 3.6578369140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.113892), ('duration', 3.4520263671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1486.748047), ('duration', 2.3319091796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1505.262085), ('duration', 3.4063720703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.439087), ('duration', 1.0516357421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1756.245117), ('duration', 4.2523193359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1807.182495), ('duration', 1.828857421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1922.290039), ('duration', 2.1490478515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.267212), ('duration', 5.3724365234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2112.381592), ('duration', 7.91015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.427246), ('duration', 3.93212890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2216.300293), ('duration', 7.27001953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2331.169922), ('duration', 2.560546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2344.951416), ('duration', 2.69775390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2499.67041), ('duration', 1.486083984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.835205), ('duration', 3.2919921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2550.506836), ('duration', 3.54345703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2649.912354), ('duration', 2.994873046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2706.953857), ('duration', 4.09228515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.044434), ('duration', 3.0634765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2913.181641), ('duration', 3.360595703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2961.087891), ('duration', 3.223388671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2998.279785), ('duration', 3.360595703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.013428), ('duration', 6.88134765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3253.579834), ('duration', 17.740478515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3347.544434), ('duration', 2.62890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3420.438232), ('duration', 2.53759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3438.906494), ('duration', 3.109130859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3501.901367), ('duration', 2.03466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3572.518799), ('duration', 1.828857421875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 315  N val: 10  N test: 10\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_11_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 78  Num of removed annots: 19  Num of retained annots:  59\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 177.039948), ('duration', 4.3952178955078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.18277), ('duration', 2.32159423828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 435.710114), ('duration', 1.48760986328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.806274), ('duration', 5.29681396484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 671.660583), ('duration', 1.893310546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.955811), ('duration', 1.44256591796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 899.639587), ('duration', 0.833984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.750732), ('duration', 1.7130126953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1206.979858), ('duration', 2.006103515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.227905), ('duration', 3.876708984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1295.597412), ('duration', 7.190185546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.611084), ('duration', 2.5694580078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1481.968506), ('duration', 2.9075927734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1580.556152), ('duration', 4.5303955078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.591431), ('duration', 6.2659912109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1637.656128), ('duration', 5.3643798828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1651.32251), ('duration', 1.5777587890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1775.785278), ('duration', 4.0797119140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1791.269775), ('duration', 18.189453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1932.201538), ('duration', 3.1329345703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.449463), ('duration', 2.38916015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2151.615479), ('duration', 2.006103515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.539551), ('duration', 1.53271484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2233.644043), ('duration', 2.34423828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2278.166992), ('duration', 9.42138671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2315.965576), ('duration', 1.6455078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2343.441162), ('duration', 7.55078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2426.551758), ('duration', 2.25390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2470.736328), ('duration', 1.623046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.974609), ('duration', 10.030029296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2551.818359), ('duration', 2.299072265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2593.869385), ('duration', 2.862548828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2637.603516), ('duration', 2.636962890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2668.505127), ('duration', 2.772216796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2705.033936), ('duration', 14.5830078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2730.661133), ('duration', 3.6064453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2771.908447), ('duration', 4.84619140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2806.206055), ('duration', 8.00146484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2829.624512), ('duration', 14.8310546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2880.150391), ('duration', 2.2314453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.381104), ('duration', 3.49365234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2907.363037), ('duration', 3.268310546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2940.218018), ('duration', 2.456787109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2961.750732), ('duration', 1.600341796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3074.462891), ('duration', 13.208251953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3097.363037), ('duration', 2.592041015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3190.803955), ('duration', 3.49365234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3207.333008), ('duration', 1.9384765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3230.285645), ('duration', 6.6943359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3262.396729), ('duration', 8.452392578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3306.897217), ('duration', 16.431396484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3346.10083), ('duration', 1.1044921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3388.452393), ('duration', 3.854248046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3416.048096), ('duration', 1.825927734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3431.630371), ('duration', 11.144287109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3490.585938), ('duration', 32.209228515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3547.460693), ('duration', 14.222412109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3602.553955), ('duration', 2.163330078125), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 371  N val: 11  N test: 11\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_12_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 51  Num of removed annots: 19  Num of retained annots:  32\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.551804), ('duration', 2.30902099609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.795807), ('duration', 1.3717041015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.433899), ('duration', 1.73748779296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.997986), ('duration', 1.92041015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.792236), ('duration', 2.78912353515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.352783), ('duration', 2.354736328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1182.130005), ('duration', 4.275146484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.908081), ('duration', 2.2633056640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.174927), ('duration', 1.6231689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.036987), ('duration', 1.9432373046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1682.048096), ('duration', 5.5782470703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.885254), ('duration', 2.7662353515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1960.644043), ('duration', 3.132080078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.518677), ('duration', 2.81201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2073.501709), ('duration', 2.0576171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2093.70752), ('duration', 2.2861328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2150.264893), ('duration', 14.699951171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2344.736328), ('duration', 3.612060546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2396.222168), ('duration', 3.657958984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2471.718506), ('duration', 2.629150390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2516.94043), ('duration', 9.78466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.397705), ('duration', 3.246337890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.067383), ('duration', 3.772216796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3015.650635), ('duration', 2.263427734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3050.07251), ('duration', 2.65185546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3061.819336), ('duration', 1.96630859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.908936), ('duration', 1.828857421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.169922), ('duration', 3.840576171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3377.466309), ('duration', 3.81787109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3403.113037), ('duration', 2.8349609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.432373), ('duration', 2.217529296875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 400  N val: 12  N test: 12\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_13_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 41  Num of removed annots: 19  Num of retained annots:  22\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.160904), ('duration', 3.20062255859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 356.484039), ('duration', 3.921905517578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 536.904724), ('duration', 2.592041015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.437378), ('duration', 3.9444580078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.459961), ('duration', 3.718994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1100.759033), ('duration', 3.290771484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1194.230103), ('duration', 4.6431884765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.822144), ('duration', 2.6822509765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1280.82666), ('duration', 6.4913330078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.520874), ('duration', 2.862548828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.734253), ('duration', 3.155517578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.175903), ('duration', 2.7799072265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1981.855835), ('duration', 3.1104736328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2161.750732), ('duration', 5.251708984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.169189), ('duration', 3.1103515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.666504), ('duration', 2.299072265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2706.213623), ('duration', 6.58154296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2892.855225), ('duration', 2.907470703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.285645), ('duration', 3.8994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.300049), ('duration', 3.51611328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3438.414795), ('duration', 4.7109375), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 419  N val: 13  N test: 13\n","Shape Trian: torch.Size([14944, 1, 129, 640])  Shape Val: torch.Size([492, 1, 129, 640])  Shape Test: torch.Size([468, 1, 129, 640])\n","-------------------------------------\n","Shape EEG Train: torch.Size([14944, 1, 128, 640])  Val: torch.Size([492, 1, 128, 640])  Test: torch.Size([468, 1, 128, 640])\n","Mean: 3.812859750151887e-11  Std: 5.517587851500139e-06\n","Shape Env Train: torch.Size([14944, 1, 1, 640])  Val: torch.Size([492, 1, 1, 640])  Test: torch.Size([468, 1, 1, 640])\n","Mean Env: 2.3703320026397705  Std Env: 2.5995824337005615\n"]}],"source":["raws_train_windowed, raws_val_windowed, raws_test_windowed = [], [], []\n","\n","for subj_id in subj_ids:\n","    \n","\n","    # load subject raw MNE object\n","    raw = mne.io.read_raw(os.path.join(after_ica_path, f'subj_{subj_id}_after_ica_raw.fif'), preload=True)\n","    # drop M1 and M2 channels\n","    raw.drop_channels(['M1', 'M2'])\n","    assert raw.info['nchan'] == n_channs\n","\n","    raw = rm_repeated_annotations(raw)\n","    annots = raw.annotations.copy()\n","    raw_split = [raw.copy().crop(t1, t2) for t1, t2 in zip(annots.onset[:-1]+annots.duration[:-1], annots.onset[1:])]\n","\n","    # Pick the split with the longest duration for validation, supposedly less noisy\n","    ix_val = np.argmax([i.get_data().shape[1] for i in raw_split])\n","    raw_val = [raw_split.pop(ix_val)] # create a list to make it iterable. later may be used for multiple splits\n","\n","    # Pick the next split with the longest duration for testing, supposedly less noisy\n","    ix_test = np.argmax([i.get_data().shape[1] for i in raw_split])\n","    raw_test = [raw_split.pop(ix_test)]\n","    \n","    # creat list of unfolded tensor raw objects\n","    fs = raw.info['sfreq']\n","    raws_train_windowed.extend([unfold_raw(i, window_size=window_size, stride=stride_size_train) for i in raw_split if i.get_data().shape[1] > window_size])\n","    raws_val_windowed.extend([unfold_raw(i, window_size=window_size, stride=stride_size_val) for i in raw_val if i.get_data().shape[1] > window_size])\n","    raws_test_windowed.extend([unfold_raw(i, window_size=window_size, stride=stride_size_test) for i in raw_test if i.get_data().shape[1] > window_size])\n","    print(\"-------------------------------------\")\n","    print('N train: %d  N val: %d  N test: %d' % (len(raws_train_windowed), len(raws_val_windowed), len(raws_test_windowed)))\n","\n","# concatenate all in second dimension\n","sigs_train = torch.cat(raws_train_windowed, dim=1).permute(1, 0, 2, 3)\n","sigs_val = torch.cat(raws_val_windowed, dim=1).permute(1, 0, 2, 3)\n","sigs_test = torch.cat(raws_test_windowed, dim=1).permute(1, 0, 2, 3)\n","print(f\"Shape Trian: {sigs_train.shape}  Shape Val: {sigs_val.shape}  Shape Test: {sigs_test.shape}\")\n","\n","eegs_train = sigs_train[:, :, :-1, :]\n","eegs_val = sigs_val[:, :, :-1, :]\n","eegs_test = sigs_test[:, :, :-1, :]\n","print(\"-------------------------------------\")\n","print(f\"Shape EEG Train: {eegs_train.shape}  Val: {eegs_val.shape}  Test: {eegs_test.shape}\")\n","\n","# To avoid information leakage, we estimate the mean and std from the training set only.\n","mean_eeg_train =  eegs_train.mean()\n","std_eeg_train = eegs_train.std()\n","print(f\"Mean: {mean_eeg_train}  Std: {std_eeg_train}\")\n","\n","envs_train = sigs_train[:, :, [-1], :]\n","envs_val = sigs_val[:, :, [-1], :]\n","envs_test = sigs_test[:, :, [-1], :]\n","print(f\"Shape Env Train: {envs_train.shape}  Val: {envs_val.shape}  Test: {envs_test.shape}\")\n","\n","# Estimate mean and std of the Envelope data set\n","mean_env_train =  envs_train.mean()\n","std_env_train = envs_train.std()\n","print(f\"Mean Env: {mean_env_train}  Std Env: {std_env_train}\")\n","\n","# Normalize the data\n","eegs_train = (eegs_train - mean_eeg_train) / std_eeg_train\n","eegs_val = (eegs_val - mean_eeg_train) / std_eeg_train\n","eegs_test = (eegs_test - mean_eeg_train) / std_eeg_train\n","\n","envs_train = (envs_train - mean_env_train) / std_env_train\n","envs_val = (envs_val - mean_env_train) / std_env_train\n","envs_test = (envs_test - mean_env_train) / std_env_train\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tesRTfOdZQe2"},"source":["### Pytorch dataloader"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1677755037158,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"HviGOmH1ZQe2"},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, eeg, env):\n","        self.eeg = eeg\n","        self.env = env\n","    \n","    def __getitem__(self, index):\n","        return self.eeg[index], self.env[index]\n","    \n","    def __len__(self):\n","        return len(self.eeg)\n","    \n","dataset_train = MyDataset(eegs_train, envs_train)\n","dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","dl_val = DataLoader(MyDataset(eegs_val, envs_val), batch_size=batch_size, shuffle=True, drop_last=True)"]},{"cell_type":"markdown","metadata":{"id":"XMjI2NeFZQe3"},"source":["## Model"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1677755037158,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"57o2oV6VZQe3"},"outputs":[],"source":["class Conv2d(nn.Conv2d):\n","    def __init__(self, in_channels, out_channels, kernel_size, **kargs):\n","        super().__init__(in_channels, out_channels, kernel_size, **kargs)\n","\n","    def __call__(self, inp):\n","        self.out = super().__call__(inp)\n","\n","        if self.out.requires_grad:\n","            self.out.retain_grad()\n","\n","        return self.out\n","    \n","    # -----------------------------------------------------------------------------------------------\n","class Flatten:\n","    \n","  def __call__(self, x):\n","    self.out = x.view(x.shape[0], -1)\n","    return self.out\n","  \n","  def parameters(self):\n","    return []\n","  \n","  # -----------------------------------------------------------------------------------------------\n","class Linear(nn.Linear):\n","    def __init__(self, x, y, **kargs):\n","        super().__init__(x, y, **kargs)\n","\n","    def __call__(self, inp):\n","        self.out = super().__call__(inp)\n","        return self.out\n","  # -----------------------------------------------------------------------------------------------\n","   \n","class ELU(nn.ELU):\n","    def __init__(self, alpha=1.0, inplace=False):\n","        super().__init__(alpha=1.0, inplace=False)\n","\n","    def __call__(self, inp):\n","        self.out = super().__call__(inp)\n","        if self.out.requires_grad:\n","            self.out.retain_grad()\n","        return self.out\n","\n","  # -----------------------------------------------------------------------------------------------\n","class Sequential:\n","  \n","    def __init__(self, layers):\n","        self.layers = layers\n","\n","    def __call__(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        self.out = x\n","        return self.out\n","\n","    def parameters(self):\n","        # get parameters of all layers and stretch them out into one list\n","        return [p for layer in self.layers for p in layer.parameters()]\n","\n","    def named_parameters(self):\n","        # get parameters of all layers and stretch them out into one list\n","        return ((n, p) for layer in self.layers for n, p in layer.named_parameters())"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1677755037159,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"IffWKmD6ZQe3"},"outputs":[],"source":["# My implementation of the shallow convnet\n","\n","fs = 64 # sampling rate\n","T = 5 * fs # number of time points in each trial\n","C = 64 # number of EEG channels\n","F1 = 8 # number of channels (depth) in the first conv layer\n","D = 2 # number of spatial filters in the second conv layer\n","F2 = D * F1 # number of channels (depth) in the pont-wise conv layer\n","num_classes = 4 # number of classes\n","\n","shallow_covnet = Sequential([\n","    Conv2d(1, 40, (1, int(fs//2)), padding='same', bias=True),\n","    Conv2d(40, 40, (C, 1), padding=(0, 0), bias=False), nn.BatchNorm2d(40, affine=True), \n","    nn.AvgPool2d((1, 75), (1, 15)), nn.Dropout(0.5),\n","    Conv2d(40, 4, kernel_size=(1, 30), padding='same', stride=(1, 1), bias=True),\n","    nn.Flatten(1, -1), # Flatten start_dim=1, end_dim=-1\n","    Linear(62*4, 4, bias=True),\n","])\n","\n"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1677755037159,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"bT-TwE-oTAHE","outputId":"9a080f12-5ca2-4094-95d3-75fc54958c5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 32])\n"]}],"source":["## EEG Encoder with LINEAR\n","\n","class EEGEncoderWithLinear(nn.Module):\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            C = 128, # number of EEG channels\n","            F1 = 8, # 8 or 4 number of channels (depth) in the first conv layer\n","            D = 2, # number of spatial filters in the second conv layer\n","            F2 = None # number of channels (depth) in the pont-wise conv layer\n","        ):\n","        super(EEGEncoderWithLinear, self).__init__()\n","\n","        if F2 is None:\n","            F2 = D * F1\n","\n","        self.eeg_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs/2)), padding='same', bias=True, groups=1),\n","            nn.BatchNorm2d(F1, affine=True),\n","            Conv2d(F1, out_channels=D*F1, kernel_size=(C, 1), padding=(0, 0), bias=False, groups=F1),\n","            nn.BatchNorm2d(D*F1, affine=True), ELU(), nn.AvgPool2d(1, 4), nn.Dropout(0.25),\n","                    \n","            Conv2d(F2, F2, (1, int(fs/(2*4))), padding='same', bias=False, groups=D*F1),\n","            Conv2d(D*F1, F2, kernel_size=(1, 1), padding=(0, 0), groups=1, bias=False),\n","            nn.BatchNorm2d(F2, affine=True), ELU(), nn.AvgPool2d(1, 8), nn.Dropout(0.25),\n","\n","            nn.Flatten(),\n","            nn.Linear(F2*int((T*fs)//(8*4)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.eeg_encoder(x)\n","        return x\n","\n","\n","def normalize_weights_eegnet(eeg_encoder):\n","\n","    for ix, (name, param) in enumerate(eeg_encoder.named_parameters()):\n","        if  name == 'weight' and param.ndim==4 and ix==1: # normalize conv weights to max norm 1\n","            param.data = torch.renorm(param.data, 2, 0, maxnorm=1)\n","        elif name == 'weight' and param.ndim==2: # normalize fc weights to max norm 0.25\n","            param.data = torch.renorm(param.data, 2, 0, maxnorm=0.25)\n","\n","\n","eeg_encoder_with_linear = EEGEncoderWithLinear()\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(eeg_encoder_with_linear(eegs_train[:32, :, :, :]).shape)\n","\n","#summary(eeg_encoder_with_linear, (1, 128, 640))"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1677755037159,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"sQjEWHA4ZQe4","outputId":"2b79eb61-d59d-40c1-df14-95cea5e6f345"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 320])\n"]}],"source":["## EEG Encoder NO LINEAR\n","\n","class EEGEncoderNoLinear(nn.Module):\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            C = 128, # number of EEG channels\n","            F1 = 8, # 8 or 4 number of channels (depth) in the first conv layer\n","            D = 2, # number of spatial filters in the second conv layer\n","            F2 = None # number of channels (depth) in the pont-wise conv layer\n","        ):\n","        super(EEGEncoderNoLinear, self).__init__()\n","\n","        if F2 is None:\n","            F2 = D * F1\n","\n","        self.eeg_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs/2)), padding='same', bias=True, groups=1),\n","            nn.BatchNorm2d(F1, affine=True),\n","            Conv2d(F1, out_channels=D*F1, kernel_size=(C, 1), padding=(0, 0), bias=False, groups=F1),\n","            nn.BatchNorm2d(D*F1, affine=True), ELU(), nn.AvgPool2d(1, 4), nn.Dropout(0.25),\n","                    \n","            Conv2d(F2, F2, (1, int(fs/(2*4))), padding='same', bias=False, groups=D*F1),\n","            Conv2d(D*F1, F2, kernel_size=(1, 1), padding=(0, 0), groups=1, bias=False),\n","            nn.BatchNorm2d(F2, affine=True), ELU(), nn.AvgPool2d(1, 8), nn.Dropout(0.25),\n","\n","            nn.Flatten(),\n","            #nn.Linear(F2*int((T*fs)//(8*4)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.eeg_encoder(x)\n","        return x\n","\n","\n","def normalize_weights_eegnet(eeg_encoder):\n","\n","    for ix, (name, param) in enumerate(eeg_encoder.named_parameters()):\n","        if  name == 'weight' and param.ndim==4 and ix==1: # normalize conv weights to max norm 1\n","            param.data = torch.renorm(param.data, 2, 0, maxnorm=1)\n","        elif name == 'weight' and param.ndim==2: # normalize fc weights to max norm 0.25\n","            param.data = torch.renorm(param.data, 2, 0, maxnorm=0.25)\n","\n","\n","eeg_encoder_no_linear = EEGEncoderNoLinear()\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(eeg_encoder_no_linear(eegs_train[:32, :, :, :]).shape)\n","\n","#summary(eeg_encoder_no_linear, (1, 128, 640))"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1677755037159,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"SfO-UwlzZQe4","outputId":"b6875d0d-87c3-4f9f-ae6c-984b288c082e"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 320])\n"]}],"source":["class EnvEncoder3ConvNoLinear(nn.Module):\n","\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            F1 = 4\n","        ):\n","        super(EnvEncoder3ConvNoLinear, self).__init__()\n","\n","        self.env_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs//2)), padding='same', bias=True),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1, (1, int(fs//4)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1*4, (1, int(fs//8)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1*4, affine=True), ELU(), nn.AvgPool2d(1, 8), nn.Dropout(0.5),\n","            nn.Flatten(),\n","            #nn.Linear(F1*int((T*fs)//(2*8)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.env_encoder(x)\n","        return x\n","\n","env_encoder3conv_no_linear = EnvEncoder3ConvNoLinear()\n","\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(env_encoder3conv_no_linear(envs_train[:32, :, :, :]).shape)\n","#summary(env_encoder3conv_no_linear, (1, 1, 640))"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1677755037160,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"EHbSd3XITAHF","outputId":"4a9ee851-d45b-417f-a914-7242ff680857"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 320])\n"]}],"source":["class EnvEncoder2ConvNoLinear(nn.Module):\n","\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            F1 = 4\n","        ):\n","        super(EnvEncoder2ConvNoLinear, self).__init__()\n","\n","        self.env_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs//2)), padding='same', bias=True),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1*4, (1, int(fs//4)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1*4, affine=True), ELU(), nn.AvgPool2d(1, 16), nn.Dropout(0.5),\n","            nn.Flatten(),\n","            #nn.Linear(F1*int((T*fs)//(2*8)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.env_encoder(x)\n","        return x\n","\n","env_encoder2conv_no_linear = EnvEncoder2ConvNoLinear()\n","\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(env_encoder2conv_no_linear(envs_train[:32, :, :, :]).shape)\n","#summary(env_encoder2conv_no_linear, (1, 1, 640))"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1677755037160,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"2914ppmhTAHG","outputId":"c2917381-8ca8-4b88-d5f2-c168ec196624"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 32])\n"]}],"source":["class EnvEncoder2ConvWithLinear(nn.Module):\n","\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            F1 = 4\n","        ):\n","        super(EnvEncoder2ConvWithLinear, self).__init__()\n","\n","        self.env_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs//2)), padding='same', bias=True),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1*4, (1, int(fs//4)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1*4, affine=True), ELU(), nn.AvgPool2d(1, 16), nn.Dropout(0.5),\n","            nn.Flatten(),\n","            nn.Linear(F1*4*int((T*fs)//(8*4)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.env_encoder(x)\n","        return x\n","\n","env_encoder2conv_with_linear = EnvEncoder2ConvWithLinear()\n","\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(env_encoder2conv_with_linear(envs_train[:32, :, :, :]).shape)\n","#summary(env_encoder2conv_with_linear, (1, 1, 640))"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1677755037160,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"ojZIx-6eTAHG","outputId":"56742df3-ae8f-42bc-d784-e8334248841d"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 32])\n"]}],"source":["class EnvEncoder3ConvWithLinear(nn.Module):\n","\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            F1 = 4\n","        ):\n","        super(EnvEncoder3ConvWithLinear, self).__init__()\n","\n","        self.env_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs//2)), padding='same', bias=True),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1, (1, int(fs//4)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1*4, (1, int(fs//8)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1*4, affine=True), ELU(), nn.AvgPool2d(1, 8), nn.Dropout(0.5),\n","            nn.Flatten(),\n","            nn.Linear(F1*4*int((T*fs)//(4*8)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.env_encoder(x)\n","        return x\n","\n","env_encoder3conv_with_linear = EnvEncoder3ConvWithLinear()\n","\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(env_encoder3conv_with_linear(envs_train[:32, :, :, :]).shape)\n","#summary(env_encoder3conv_with_linear, (1, 1, 640))"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1677755037160,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"Bp8HVS-aZQe4","outputId":"7953a71b-f4fa-4b57-8d9a-11ce68cded72"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CES()"]},"metadata":{},"execution_count":44}],"source":["class CES(nn.Module):\n","    def __init__(self, \n","                 eeg_encoder= None,\n","                 env_encoder = None): \n","        super().__init__()\n","\n","        self.eeg_encoder = eeg_encoder\n","        self.env_encoder = env_encoder\n","        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n","\n","    def encode_eeg(self, x):\n","        return self.eeg_encoder(x)\n","    \n","    def encode_env(self, x):\n","        return self.env_encoder(x)\n","    \n","    def forward(self, eeg, env):\n","        eeg_features = self.encode_eeg(eeg)\n","        env_features = self.encode_env(env)\n","        return eeg_features, env_features, self.logit_scale.exp()\n","  \n","\n","model = CES();\n","model.to(device)\n","#for n,p in model.named_parameters():\n","    #print(n, p.shape)\n"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":741,"status":"ok","timestamp":1677755037884,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"kRK-Pq1VTAHG","outputId":"47d04e85-9933-45d6-de07-ae8d62fa280a"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Models with no Linear Layers\n"," Models with Linear Layers\n"]}],"source":["print(\" Models with no Linear Layers\")\n","eeg_encoder_no_linear = EEGEncoderNoLinear()\n","env_encoder3conv_no_linear = EnvEncoder2ConvNoLinear()\n","ces_eeg_0lin_env_3conv_0lin = CES(eeg_encoder=eeg_encoder_no_linear.eeg_encoder, env_encoder=env_encoder2conv_no_linear.env_encoder)\n","#summary(ces_eeg_0lin_env_3conv_0lin, [(1, 128, 640), (1, 1, 640)])\n","\n","eeg_encoder_no_linear = EEGEncoderNoLinear()\n","env_encoder2conv_no_linear = EnvEncoder2ConvNoLinear()\n","ces_eeg_0lin_env_2conv_0lin = CES(eeg_encoder=eeg_encoder_no_linear.eeg_encoder, env_encoder=env_encoder2conv_no_linear.env_encoder)\n","#summary(ces_eeg_0lin_env_2conv_0lin, [(1, 128, 640), (1, 1, 640)])\n","\n","\n","print(\" Models with Linear Layers\")\n","eeg_encoder_with_linear = EEGEncoderWithLinear()\n","env_encoder3conv_with_linear = EnvEncoder2ConvWithLinear()\n","ces_eeg_1lin_env_3conv_1lin = CES(eeg_encoder=eeg_encoder_with_linear.eeg_encoder, env_encoder=env_encoder3conv_with_linear.env_encoder)\n","#summary(ces_eeg_1lin_env_3conv_1lin, [(1, 128, 640), (1, 1, 640)])\n","\n","eeg_encoder_with_linear = EEGEncoderWithLinear()\n","env_encoder2conv_with_linear = EnvEncoder2ConvWithLinear()\n","ces_eeg_1lin_env_2conv_1lin = CES(eeg_encoder=eeg_encoder_with_linear.eeg_encoder, env_encoder=env_encoder2conv_with_linear.env_encoder)\n","#summary(ces_eeg_1lin_env_2conv_1lin, [(1, 128, 640), (1, 1, 640)])\n","\n","models_name = [\"eeg0lin_env3conv0lin\", \"eeg0lin_env2conv0lin\"]#, \"eeg1lin_env3conv1lin\", \"eeg1lin_env2conv1lin\"]\n","models_dict = {\"eeg0lin_env3conv0lin\": ces_eeg_0lin_env_3conv_0lin, \"eeg0lin_env2conv0lin\": ces_eeg_0lin_env_2conv_0lin} #, \n","              # \"eeg1lin_env3conv1lin\": ces_eeg_1lin_env_3conv_1lin, \"eeg1lin_env2conv1lin\": ces_eeg_1lin_env_2conv_1lin}\n"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4837817,"status":"ok","timestamp":1677759875695,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"d4iJiosNZQe7","outputId":"4e07874e-0ab6-4537-8520-121aa644b813"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------New model: eeg0lin_env3conv0lin----------------------+\n","====== Epoch: 1\n","====> Validation loss: 3.2820,  X1 loss: 3.2745   X2 loss: 3.2895\n","====== Epoch: 2\n","====> Validation loss: 3.1254,  X1 loss: 3.1161   X2 loss: 3.1347\n","====== Epoch: 3\n","====> Validation loss: 3.0973,  X1 loss: 3.0905   X2 loss: 3.1042\n","====== Epoch: 4\n","====> Validation loss: 3.0906,  X1 loss: 3.0802   X2 loss: 3.1010\n","====== Epoch: 5\n","====> Validation loss: 3.0107,  X1 loss: 3.0100   X2 loss: 3.0115\n","====== Epoch: 6\n","====> Validation loss: 2.9563,  X1 loss: 2.9510   X2 loss: 2.9616\n","====== Epoch: 7\n","====> Validation loss: 2.9633,  X1 loss: 2.9585   X2 loss: 2.9682\n","====== Epoch: 8\n","====> Validation loss: 2.9234,  X1 loss: 2.9169   X2 loss: 2.9299\n","====== Epoch: 9\n","====> Validation loss: 2.9160,  X1 loss: 2.8973   X2 loss: 2.9348\n","====== Epoch: 10\n","====> Validation loss: 2.9198,  X1 loss: 2.9155   X2 loss: 2.9241\n","====== Epoch: 11\n","====> Validation loss: 2.9055,  X1 loss: 2.9024   X2 loss: 2.9087\n","====== Epoch: 12\n","====> Validation loss: 2.8775,  X1 loss: 2.8743   X2 loss: 2.8806\n","====== Epoch: 13\n","====> Validation loss: 2.9374,  X1 loss: 2.9311   X2 loss: 2.9437\n","====== Epoch: 14\n","====> Validation loss: 2.8919,  X1 loss: 2.8888   X2 loss: 2.8950\n","====== Epoch: 15\n","====> Validation loss: 2.8906,  X1 loss: 2.8897   X2 loss: 2.8915\n","====== Epoch: 16\n","====> Validation loss: 2.8623,  X1 loss: 2.8603   X2 loss: 2.8644\n","====== Epoch: 17\n","====> Validation loss: 2.8619,  X1 loss: 2.8487   X2 loss: 2.8751\n","====== Epoch: 18\n","====> Validation loss: 2.9036,  X1 loss: 2.8924   X2 loss: 2.9147\n","====== Epoch: 19\n","====> Validation loss: 2.8731,  X1 loss: 2.8629   X2 loss: 2.8832\n","====== Epoch: 20\n","====> Validation loss: 2.8479,  X1 loss: 2.8441   X2 loss: 2.8517\n","====== Epoch: 21\n","====> Validation loss: 2.8091,  X1 loss: 2.8042   X2 loss: 2.8141\n","====== Epoch: 22\n","====> Validation loss: 2.8779,  X1 loss: 2.8719   X2 loss: 2.8838\n","====== Epoch: 23\n","====> Validation loss: 2.8547,  X1 loss: 2.8361   X2 loss: 2.8732\n","====== Epoch: 24\n","====> Validation loss: 2.9154,  X1 loss: 2.9040   X2 loss: 2.9269\n","====== Epoch: 25\n","====> Validation loss: 2.8204,  X1 loss: 2.8101   X2 loss: 2.8306\n","====== Epoch: 26\n","====> Validation loss: 2.8423,  X1 loss: 2.8333   X2 loss: 2.8512\n","====== Epoch: 27\n","====> Validation loss: 2.8287,  X1 loss: 2.8167   X2 loss: 2.8407\n","====== Epoch: 28\n","====> Validation loss: 2.8082,  X1 loss: 2.7985   X2 loss: 2.8178\n","====== Epoch: 29\n","====> Validation loss: 2.8122,  X1 loss: 2.7989   X2 loss: 2.8254\n","====== Epoch: 30\n","====> Validation loss: 2.8314,  X1 loss: 2.8213   X2 loss: 2.8415\n","====== Epoch: 31\n","====> Validation loss: 2.8207,  X1 loss: 2.8058   X2 loss: 2.8355\n","====== Epoch: 32\n","====> Validation loss: 2.8173,  X1 loss: 2.8018   X2 loss: 2.8328\n","====== Epoch: 33\n","====> Validation loss: 2.8507,  X1 loss: 2.8374   X2 loss: 2.8639\n","====== Epoch: 34\n","====> Validation loss: 2.8044,  X1 loss: 2.7983   X2 loss: 2.8105\n","====== Epoch: 35\n","====> Validation loss: 2.8194,  X1 loss: 2.8118   X2 loss: 2.8270\n","====== Epoch: 36\n","====> Validation loss: 2.8733,  X1 loss: 2.8560   X2 loss: 2.8905\n","====== Epoch: 37\n","====> Validation loss: 2.7907,  X1 loss: 2.7852   X2 loss: 2.7961\n","====== Epoch: 38\n","====> Validation loss: 2.7570,  X1 loss: 2.7383   X2 loss: 2.7757\n","====== Epoch: 39\n","====> Validation loss: 2.8282,  X1 loss: 2.8056   X2 loss: 2.8508\n","====== Epoch: 40\n","====> Validation loss: 2.7871,  X1 loss: 2.7825   X2 loss: 2.7918\n","====== Epoch: 41\n","====> Validation loss: 2.8500,  X1 loss: 2.8437   X2 loss: 2.8563\n","====== Epoch: 42\n","====> Validation loss: 2.7819,  X1 loss: 2.7690   X2 loss: 2.7948\n","====== Epoch: 43\n","====> Validation loss: 2.8241,  X1 loss: 2.8071   X2 loss: 2.8412\n","====== Epoch: 44\n","====> Validation loss: 2.7950,  X1 loss: 2.7846   X2 loss: 2.8054\n","====== Epoch: 45\n","====> Validation loss: 2.8223,  X1 loss: 2.8143   X2 loss: 2.8303\n","====== Epoch: 46\n","====> Validation loss: 2.8127,  X1 loss: 2.7932   X2 loss: 2.8321\n","====== Epoch: 47\n","====> Validation loss: 2.7781,  X1 loss: 2.7646   X2 loss: 2.7915\n","====== Epoch: 48\n","====> Validation loss: 2.7743,  X1 loss: 2.7675   X2 loss: 2.7811\n","====== Epoch: 49\n","====> Validation loss: 2.7973,  X1 loss: 2.7907   X2 loss: 2.8039\n","====== Epoch: 50\n","====> Validation loss: 2.8125,  X1 loss: 2.8008   X2 loss: 2.8242\n","====== Epoch: 51\n","====> Validation loss: 2.8255,  X1 loss: 2.8157   X2 loss: 2.8353\n","====== Epoch: 52\n","====> Validation loss: 2.7906,  X1 loss: 2.7714   X2 loss: 2.8097\n","====== Epoch: 53\n","====> Validation loss: 2.7659,  X1 loss: 2.7584   X2 loss: 2.7734\n","====== Epoch: 54\n","====> Validation loss: 2.8169,  X1 loss: 2.8053   X2 loss: 2.8285\n","====== Epoch: 55\n","====> Validation loss: 2.7346,  X1 loss: 2.7230   X2 loss: 2.7462\n","====== Epoch: 56\n","====> Validation loss: 2.7457,  X1 loss: 2.7344   X2 loss: 2.7570\n","====== Epoch: 57\n","====> Validation loss: 2.7772,  X1 loss: 2.7467   X2 loss: 2.8077\n","====== Epoch: 58\n","====> Validation loss: 2.7223,  X1 loss: 2.7075   X2 loss: 2.7371\n","====== Epoch: 59\n","====> Validation loss: 2.6987,  X1 loss: 2.6798   X2 loss: 2.7177\n","====== Epoch: 60\n","====> Validation loss: 2.7343,  X1 loss: 2.7230   X2 loss: 2.7456\n","====== Epoch: 61\n","====> Validation loss: 2.7036,  X1 loss: 2.6804   X2 loss: 2.7269\n","====== Epoch: 62\n","====> Validation loss: 2.6849,  X1 loss: 2.6706   X2 loss: 2.6993\n","====== Epoch: 63\n","====> Validation loss: 2.7447,  X1 loss: 2.7234   X2 loss: 2.7659\n","====== Epoch: 64\n","====> Validation loss: 2.7349,  X1 loss: 2.7107   X2 loss: 2.7591\n","====== Epoch: 65\n","====> Validation loss: 2.7317,  X1 loss: 2.7161   X2 loss: 2.7473\n","====== Epoch: 66\n","====> Validation loss: 2.7742,  X1 loss: 2.7422   X2 loss: 2.8062\n","====== Epoch: 67\n","====> Validation loss: 2.7865,  X1 loss: 2.7586   X2 loss: 2.8143\n","====== Epoch: 68\n","====> Validation loss: 2.7697,  X1 loss: 2.7556   X2 loss: 2.7837\n","====== Epoch: 69\n","====> Validation loss: 2.7365,  X1 loss: 2.7235   X2 loss: 2.7496\n","====== Epoch: 70\n","====> Validation loss: 2.7766,  X1 loss: 2.7641   X2 loss: 2.7890\n","====== Epoch: 71\n","====> Validation loss: 2.7622,  X1 loss: 2.7456   X2 loss: 2.7788\n","====== Epoch: 72\n","====> Validation loss: 2.7442,  X1 loss: 2.7337   X2 loss: 2.7547\n","====== Epoch: 73\n","====> Validation loss: 2.7193,  X1 loss: 2.7019   X2 loss: 2.7367\n","====== Epoch: 74\n","====> Validation loss: 2.7457,  X1 loss: 2.7167   X2 loss: 2.7748\n","====== Epoch: 75\n","====> Validation loss: 2.7598,  X1 loss: 2.7454   X2 loss: 2.7742\n","====== Epoch: 76\n","====> Validation loss: 2.7642,  X1 loss: 2.7536   X2 loss: 2.7747\n","====== Epoch: 77\n","====> Validation loss: 2.7186,  X1 loss: 2.6989   X2 loss: 2.7383\n","====== Epoch: 78\n","====> Validation loss: 2.8037,  X1 loss: 2.7888   X2 loss: 2.8187\n","====== Epoch: 79\n","====> Validation loss: 2.7766,  X1 loss: 2.7629   X2 loss: 2.7903\n","====== Epoch: 80\n","====> Validation loss: 2.7372,  X1 loss: 2.7192   X2 loss: 2.7552\n","====== Epoch: 81\n","====> Validation loss: 2.7393,  X1 loss: 2.7235   X2 loss: 2.7551\n","====== Epoch: 82\n","====> Validation loss: 2.7255,  X1 loss: 2.7073   X2 loss: 2.7436\n","====== Epoch: 83\n","====> Validation loss: 2.7052,  X1 loss: 2.6909   X2 loss: 2.7195\n","====== Epoch: 84\n","====> Validation loss: 2.7153,  X1 loss: 2.6995   X2 loss: 2.7311\n","====== Epoch: 85\n","====> Validation loss: 2.7103,  X1 loss: 2.6955   X2 loss: 2.7252\n","====== Epoch: 86\n","====> Validation loss: 2.7080,  X1 loss: 2.6799   X2 loss: 2.7361\n","====== Epoch: 87\n","====> Validation loss: 2.7182,  X1 loss: 2.6991   X2 loss: 2.7372\n","====== Epoch: 88\n","====> Validation loss: 2.6973,  X1 loss: 2.6884   X2 loss: 2.7061\n","====== Epoch: 89\n","====> Validation loss: 2.7193,  X1 loss: 2.7038   X2 loss: 2.7347\n","====== Epoch: 90\n","====> Validation loss: 2.7330,  X1 loss: 2.7123   X2 loss: 2.7537\n","====== Epoch: 91\n","====> Validation loss: 2.7393,  X1 loss: 2.7180   X2 loss: 2.7607\n","====== Epoch: 92\n","====> Validation loss: 2.7399,  X1 loss: 2.7290   X2 loss: 2.7508\n","====== Epoch: 93\n","====> Validation loss: 2.7208,  X1 loss: 2.7099   X2 loss: 2.7317\n","====== Epoch: 94\n","====> Validation loss: 2.7358,  X1 loss: 2.7242   X2 loss: 2.7475\n","====== Epoch: 95\n","====> Validation loss: 2.7033,  X1 loss: 2.6792   X2 loss: 2.7273\n","====== Epoch: 96\n","====> Validation loss: 2.7446,  X1 loss: 2.7347   X2 loss: 2.7545\n","====== Epoch: 97\n","====> Validation loss: 2.7073,  X1 loss: 2.6972   X2 loss: 2.7174\n","====== Epoch: 98\n","====> Validation loss: 2.7694,  X1 loss: 2.7481   X2 loss: 2.7907\n","====== Epoch: 99\n","====> Validation loss: 2.7097,  X1 loss: 2.6891   X2 loss: 2.7302\n","====== Epoch: 100\n","====> Validation loss: 2.6941,  X1 loss: 2.6845   X2 loss: 2.7036\n","====== Epoch: 101\n","====> Validation loss: 2.7159,  X1 loss: 2.7071   X2 loss: 2.7247\n","====== Epoch: 102\n","====> Validation loss: 2.7256,  X1 loss: 2.7076   X2 loss: 2.7436\n","====== Epoch: 103\n","====> Validation loss: 2.6823,  X1 loss: 2.6777   X2 loss: 2.6868\n","====== Epoch: 104\n","====> Validation loss: 2.7231,  X1 loss: 2.7116   X2 loss: 2.7346\n","====== Epoch: 105\n","====> Validation loss: 2.7096,  X1 loss: 2.7067   X2 loss: 2.7124\n","====== Epoch: 106\n","====> Validation loss: 2.7585,  X1 loss: 2.7582   X2 loss: 2.7588\n","====== Epoch: 107\n","====> Validation loss: 2.7639,  X1 loss: 2.7503   X2 loss: 2.7775\n","====== Epoch: 108\n","====> Validation loss: 2.7207,  X1 loss: 2.6955   X2 loss: 2.7459\n","====== Epoch: 109\n","====> Validation loss: 2.7252,  X1 loss: 2.7051   X2 loss: 2.7452\n","====== Epoch: 110\n","====> Validation loss: 2.6817,  X1 loss: 2.6742   X2 loss: 2.6893\n","====== Epoch: 111\n","====> Validation loss: 2.7076,  X1 loss: 2.6902   X2 loss: 2.7249\n","====== Epoch: 112\n","====> Validation loss: 2.7721,  X1 loss: 2.7554   X2 loss: 2.7888\n","====== Epoch: 113\n","====> Validation loss: 2.6987,  X1 loss: 2.6813   X2 loss: 2.7161\n","====== Epoch: 114\n","====> Validation loss: 2.7234,  X1 loss: 2.7065   X2 loss: 2.7403\n","====== Epoch: 115\n","====> Validation loss: 2.6975,  X1 loss: 2.6860   X2 loss: 2.7090\n","====== Epoch: 116\n","====> Validation loss: 2.6657,  X1 loss: 2.6407   X2 loss: 2.6906\n","====== Epoch: 117\n","====> Validation loss: 2.7418,  X1 loss: 2.7307   X2 loss: 2.7530\n","====== Epoch: 118\n","====> Validation loss: 2.7008,  X1 loss: 2.6897   X2 loss: 2.7120\n","====== Epoch: 119\n","====> Validation loss: 2.7054,  X1 loss: 2.6895   X2 loss: 2.7213\n","====== Epoch: 120\n","====> Validation loss: 2.7118,  X1 loss: 2.7074   X2 loss: 2.7163\n","====== Epoch: 121\n","====> Validation loss: 2.7248,  X1 loss: 2.7055   X2 loss: 2.7440\n","====== Epoch: 122\n","====> Validation loss: 2.6469,  X1 loss: 2.6315   X2 loss: 2.6624\n","====== Epoch: 123\n","====> Validation loss: 2.7105,  X1 loss: 2.6803   X2 loss: 2.7408\n","====== Epoch: 124\n","====> Validation loss: 2.6778,  X1 loss: 2.6612   X2 loss: 2.6944\n","====== Epoch: 125\n","====> Validation loss: 2.7239,  X1 loss: 2.6976   X2 loss: 2.7502\n","====== Epoch: 126\n","====> Validation loss: 2.6931,  X1 loss: 2.6871   X2 loss: 2.6991\n","====== Epoch: 127\n","====> Validation loss: 2.7143,  X1 loss: 2.7002   X2 loss: 2.7283\n","====== Epoch: 128\n","====> Validation loss: 2.6859,  X1 loss: 2.6717   X2 loss: 2.7001\n","====== Epoch: 129\n","====> Validation loss: 2.6549,  X1 loss: 2.6271   X2 loss: 2.6827\n","====== Epoch: 130\n","====> Validation loss: 2.6789,  X1 loss: 2.6692   X2 loss: 2.6887\n","====== Epoch: 131\n","====> Validation loss: 2.6990,  X1 loss: 2.6869   X2 loss: 2.7111\n","====== Epoch: 132\n","====> Validation loss: 2.7212,  X1 loss: 2.7025   X2 loss: 2.7398\n","====== Epoch: 133\n","====> Validation loss: 2.7205,  X1 loss: 2.7005   X2 loss: 2.7405\n","====== Epoch: 134\n","====> Validation loss: 2.7255,  X1 loss: 2.7095   X2 loss: 2.7415\n","====== Epoch: 135\n","====> Validation loss: 2.6603,  X1 loss: 2.6368   X2 loss: 2.6837\n","====== Epoch: 136\n","====> Validation loss: 2.7195,  X1 loss: 2.7028   X2 loss: 2.7361\n","====== Epoch: 137\n","====> Validation loss: 2.6402,  X1 loss: 2.6244   X2 loss: 2.6559\n","====== Epoch: 138\n","====> Validation loss: 2.6810,  X1 loss: 2.6647   X2 loss: 2.6974\n","====== Epoch: 139\n","====> Validation loss: 2.7148,  X1 loss: 2.6907   X2 loss: 2.7388\n","====== Epoch: 140\n","====> Validation loss: 2.6532,  X1 loss: 2.6398   X2 loss: 2.6667\n","====== Epoch: 141\n","====> Validation loss: 2.6549,  X1 loss: 2.6480   X2 loss: 2.6619\n","====== Epoch: 142\n","====> Validation loss: 2.6752,  X1 loss: 2.6653   X2 loss: 2.6851\n","====== Epoch: 143\n","====> Validation loss: 2.7443,  X1 loss: 2.7263   X2 loss: 2.7623\n","====== Epoch: 144\n","====> Validation loss: 2.6974,  X1 loss: 2.6860   X2 loss: 2.7088\n","====== Epoch: 145\n","====> Validation loss: 2.7250,  X1 loss: 2.7155   X2 loss: 2.7346\n","====== Epoch: 146\n","====> Validation loss: 2.6463,  X1 loss: 2.6307   X2 loss: 2.6619\n","====== Epoch: 147\n","====> Validation loss: 2.6644,  X1 loss: 2.6429   X2 loss: 2.6860\n","====== Epoch: 148\n","====> Validation loss: 2.6622,  X1 loss: 2.6592   X2 loss: 2.6652\n","====== Epoch: 149\n","====> Validation loss: 2.6789,  X1 loss: 2.6648   X2 loss: 2.6929\n","====== Epoch: 150\n","====> Validation loss: 2.6776,  X1 loss: 2.6644   X2 loss: 2.6908\n","====== Epoch: 151\n","====> Validation loss: 2.6911,  X1 loss: 2.6686   X2 loss: 2.7135\n","====== Epoch: 152\n","====> Validation loss: 2.7258,  X1 loss: 2.7057   X2 loss: 2.7459\n","====== Epoch: 153\n","====> Validation loss: 2.6941,  X1 loss: 2.6701   X2 loss: 2.7182\n","====== Epoch: 154\n","====> Validation loss: 2.6467,  X1 loss: 2.6262   X2 loss: 2.6672\n","====== Epoch: 155\n","====> Validation loss: 2.6511,  X1 loss: 2.6299   X2 loss: 2.6723\n","====== Epoch: 156\n","====> Validation loss: 2.6638,  X1 loss: 2.6519   X2 loss: 2.6758\n","====== Epoch: 157\n","====> Validation loss: 2.6485,  X1 loss: 2.6356   X2 loss: 2.6615\n","====== Epoch: 158\n","====> Validation loss: 2.6572,  X1 loss: 2.6391   X2 loss: 2.6754\n","====== Epoch: 159\n","====> Validation loss: 2.6934,  X1 loss: 2.6753   X2 loss: 2.7115\n","====== Epoch: 160\n","====> Validation loss: 2.7043,  X1 loss: 2.6903   X2 loss: 2.7183\n","====== Epoch: 161\n","====> Validation loss: 2.6731,  X1 loss: 2.6549   X2 loss: 2.6914\n","====== Epoch: 162\n","====> Validation loss: 2.6884,  X1 loss: 2.6764   X2 loss: 2.7004\n","====== Epoch: 163\n","====> Validation loss: 2.7001,  X1 loss: 2.6764   X2 loss: 2.7239\n","====== Epoch: 164\n","====> Validation loss: 2.6915,  X1 loss: 2.6756   X2 loss: 2.7073\n","====== Epoch: 165\n","====> Validation loss: 2.6761,  X1 loss: 2.6543   X2 loss: 2.6979\n","====== Epoch: 166\n","====> Validation loss: 2.6875,  X1 loss: 2.6649   X2 loss: 2.7100\n","====== Epoch: 167\n","====> Validation loss: 2.7373,  X1 loss: 2.7065   X2 loss: 2.7681\n","====== Epoch: 168\n","====> Validation loss: 2.7184,  X1 loss: 2.7091   X2 loss: 2.7278\n","====== Epoch: 169\n","====> Validation loss: 2.6725,  X1 loss: 2.6621   X2 loss: 2.6830\n","====== Epoch: 170\n","====> Validation loss: 2.7196,  X1 loss: 2.7056   X2 loss: 2.7335\n","====== Epoch: 171\n","====> Validation loss: 2.6557,  X1 loss: 2.6405   X2 loss: 2.6710\n","====== Epoch: 172\n","====> Validation loss: 2.6631,  X1 loss: 2.6531   X2 loss: 2.6732\n","====== Epoch: 173\n","====> Validation loss: 2.7093,  X1 loss: 2.6928   X2 loss: 2.7258\n","====== Epoch: 174\n","====> Validation loss: 2.6764,  X1 loss: 2.6545   X2 loss: 2.6982\n","====== Epoch: 175\n","====> Validation loss: 2.7140,  X1 loss: 2.6890   X2 loss: 2.7390\n","====== Epoch: 176\n","====> Validation loss: 2.6304,  X1 loss: 2.6132   X2 loss: 2.6475\n","====== Epoch: 177\n","====> Validation loss: 2.6935,  X1 loss: 2.6824   X2 loss: 2.7046\n","====== Epoch: 178\n","====> Validation loss: 2.6594,  X1 loss: 2.6419   X2 loss: 2.6769\n","====== Epoch: 179\n","====> Validation loss: 2.7320,  X1 loss: 2.7144   X2 loss: 2.7496\n","====== Epoch: 180\n","====> Validation loss: 2.6829,  X1 loss: 2.6638   X2 loss: 2.7021\n","====== Epoch: 181\n","====> Validation loss: 2.6654,  X1 loss: 2.6541   X2 loss: 2.6767\n","====== Epoch: 182\n","====> Validation loss: 2.6936,  X1 loss: 2.6750   X2 loss: 2.7121\n","====== Epoch: 183\n","====> Validation loss: 2.6769,  X1 loss: 2.6611   X2 loss: 2.6928\n","====== Epoch: 184\n","====> Validation loss: 2.6586,  X1 loss: 2.6393   X2 loss: 2.6778\n","====== Epoch: 185\n","====> Validation loss: 2.6598,  X1 loss: 2.6471   X2 loss: 2.6725\n","====== Epoch: 186\n","====> Validation loss: 2.6568,  X1 loss: 2.6390   X2 loss: 2.6745\n","====== Epoch: 187\n","====> Validation loss: 2.6546,  X1 loss: 2.6345   X2 loss: 2.6747\n","====== Epoch: 188\n","====> Validation loss: 2.6599,  X1 loss: 2.6295   X2 loss: 2.6902\n","====== Epoch: 189\n","====> Validation loss: 2.6678,  X1 loss: 2.6637   X2 loss: 2.6719\n","====== Epoch: 190\n","====> Validation loss: 2.6797,  X1 loss: 2.6522   X2 loss: 2.7072\n","====== Epoch: 191\n","====> Validation loss: 2.6793,  X1 loss: 2.6647   X2 loss: 2.6939\n","====== Epoch: 192\n","====> Validation loss: 2.7092,  X1 loss: 2.6888   X2 loss: 2.7296\n","====== Epoch: 193\n","====> Validation loss: 2.6558,  X1 loss: 2.6417   X2 loss: 2.6699\n","====== Epoch: 194\n","====> Validation loss: 2.6919,  X1 loss: 2.6802   X2 loss: 2.7036\n","====== Epoch: 195\n","====> Validation loss: 2.6989,  X1 loss: 2.6830   X2 loss: 2.7149\n","====== Epoch: 196\n","====> Validation loss: 2.6844,  X1 loss: 2.6614   X2 loss: 2.7074\n","====== Epoch: 197\n","====> Validation loss: 2.6917,  X1 loss: 2.6645   X2 loss: 2.7189\n","====== Epoch: 198\n","====> Validation loss: 2.6823,  X1 loss: 2.6680   X2 loss: 2.6967\n","====== Epoch: 199\n","====> Validation loss: 2.6670,  X1 loss: 2.6375   X2 loss: 2.6966\n","+--------------New model: eeg0lin_env2conv0lin----------------------+\n","====== Epoch: 1\n","====> Validation loss: 3.2189,  X1 loss: 3.2088   X2 loss: 3.2291\n","====== Epoch: 2\n","====> Validation loss: 3.0943,  X1 loss: 3.0837   X2 loss: 3.1050\n","====== Epoch: 3\n","====> Validation loss: 3.0310,  X1 loss: 3.0285   X2 loss: 3.0335\n","====== Epoch: 4\n","====> Validation loss: 3.0022,  X1 loss: 2.9927   X2 loss: 3.0118\n","====== Epoch: 5\n","====> Validation loss: 3.0435,  X1 loss: 3.0343   X2 loss: 3.0527\n","====== Epoch: 6\n","====> Validation loss: 2.9559,  X1 loss: 2.9490   X2 loss: 2.9629\n","====== Epoch: 7\n","====> Validation loss: 2.9950,  X1 loss: 2.9866   X2 loss: 3.0034\n","====== Epoch: 8\n","====> Validation loss: 2.9819,  X1 loss: 2.9771   X2 loss: 2.9867\n","====== Epoch: 9\n","====> Validation loss: 2.8844,  X1 loss: 2.8801   X2 loss: 2.8887\n","====== Epoch: 10\n","====> Validation loss: 2.9362,  X1 loss: 2.9323   X2 loss: 2.9402\n","====== Epoch: 11\n","====> Validation loss: 2.8935,  X1 loss: 2.8897   X2 loss: 2.8973\n","====== Epoch: 12\n","====> Validation loss: 2.8926,  X1 loss: 2.8766   X2 loss: 2.9085\n","====== Epoch: 13\n","====> Validation loss: 2.9093,  X1 loss: 2.9013   X2 loss: 2.9173\n","====== Epoch: 14\n","====> Validation loss: 2.8709,  X1 loss: 2.8635   X2 loss: 2.8783\n","====== Epoch: 15\n","====> Validation loss: 2.8376,  X1 loss: 2.8291   X2 loss: 2.8461\n","====== Epoch: 16\n","====> Validation loss: 2.9174,  X1 loss: 2.9044   X2 loss: 2.9304\n","====== Epoch: 17\n","====> Validation loss: 2.8443,  X1 loss: 2.8425   X2 loss: 2.8461\n","====== Epoch: 18\n","====> Validation loss: 2.8558,  X1 loss: 2.8461   X2 loss: 2.8655\n","====== Epoch: 19\n","====> Validation loss: 2.8852,  X1 loss: 2.8799   X2 loss: 2.8904\n","====== Epoch: 20\n","====> Validation loss: 2.8759,  X1 loss: 2.8632   X2 loss: 2.8885\n","====== Epoch: 21\n","====> Validation loss: 2.8771,  X1 loss: 2.8656   X2 loss: 2.8886\n","====== Epoch: 22\n","====> Validation loss: 2.8657,  X1 loss: 2.8528   X2 loss: 2.8786\n","====== Epoch: 23\n","====> Validation loss: 2.8616,  X1 loss: 2.8490   X2 loss: 2.8743\n","====== Epoch: 24\n","====> Validation loss: 2.8778,  X1 loss: 2.8685   X2 loss: 2.8870\n","====== Epoch: 25\n","====> Validation loss: 2.8320,  X1 loss: 2.8253   X2 loss: 2.8387\n","====== Epoch: 26\n","====> Validation loss: 2.8648,  X1 loss: 2.8505   X2 loss: 2.8791\n","====== Epoch: 27\n","====> Validation loss: 2.8575,  X1 loss: 2.8496   X2 loss: 2.8653\n","====== Epoch: 28\n","====> Validation loss: 2.8468,  X1 loss: 2.8379   X2 loss: 2.8556\n","====== Epoch: 29\n","====> Validation loss: 2.8423,  X1 loss: 2.8346   X2 loss: 2.8501\n","====== Epoch: 30\n","====> Validation loss: 2.8669,  X1 loss: 2.8524   X2 loss: 2.8813\n","====== Epoch: 31\n","====> Validation loss: 2.7992,  X1 loss: 2.7894   X2 loss: 2.8090\n","====== Epoch: 32\n","====> Validation loss: 2.8472,  X1 loss: 2.8412   X2 loss: 2.8533\n","====== Epoch: 33\n","====> Validation loss: 2.8902,  X1 loss: 2.8656   X2 loss: 2.9148\n","====== Epoch: 34\n","====> Validation loss: 2.8448,  X1 loss: 2.8306   X2 loss: 2.8591\n","====== Epoch: 35\n","====> Validation loss: 2.8648,  X1 loss: 2.8578   X2 loss: 2.8718\n","====== Epoch: 36\n","====> Validation loss: 2.8524,  X1 loss: 2.8471   X2 loss: 2.8577\n","====== Epoch: 37\n","====> Validation loss: 2.8492,  X1 loss: 2.8400   X2 loss: 2.8583\n","====== Epoch: 38\n","====> Validation loss: 2.8451,  X1 loss: 2.8211   X2 loss: 2.8691\n","====== Epoch: 39\n","====> Validation loss: 2.8386,  X1 loss: 2.8255   X2 loss: 2.8518\n","====== Epoch: 40\n","====> Validation loss: 2.8346,  X1 loss: 2.8289   X2 loss: 2.8403\n","====== Epoch: 41\n","====> Validation loss: 2.8517,  X1 loss: 2.8350   X2 loss: 2.8685\n","====== Epoch: 42\n","====> Validation loss: 2.8732,  X1 loss: 2.8603   X2 loss: 2.8860\n","====== Epoch: 43\n","====> Validation loss: 2.8907,  X1 loss: 2.8773   X2 loss: 2.9042\n","====== Epoch: 44\n","====> Validation loss: 2.8666,  X1 loss: 2.8592   X2 loss: 2.8739\n","====== Epoch: 45\n","====> Validation loss: 2.9178,  X1 loss: 2.9010   X2 loss: 2.9347\n","====== Epoch: 46\n","====> Validation loss: 2.8397,  X1 loss: 2.8237   X2 loss: 2.8556\n","====== Epoch: 47\n","====> Validation loss: 2.7920,  X1 loss: 2.7791   X2 loss: 2.8048\n","====== Epoch: 48\n","====> Validation loss: 2.8044,  X1 loss: 2.8021   X2 loss: 2.8067\n","====== Epoch: 49\n","====> Validation loss: 2.8677,  X1 loss: 2.8588   X2 loss: 2.8767\n","====== Epoch: 50\n","====> Validation loss: 2.8302,  X1 loss: 2.8178   X2 loss: 2.8427\n","====== Epoch: 51\n","====> Validation loss: 2.8869,  X1 loss: 2.8757   X2 loss: 2.8982\n","====== Epoch: 52\n","====> Validation loss: 2.8655,  X1 loss: 2.8557   X2 loss: 2.8753\n","====== Epoch: 53\n","====> Validation loss: 2.8301,  X1 loss: 2.8082   X2 loss: 2.8521\n","====== Epoch: 54\n","====> Validation loss: 2.8355,  X1 loss: 2.8277   X2 loss: 2.8433\n","====== Epoch: 55\n","====> Validation loss: 2.8293,  X1 loss: 2.8290   X2 loss: 2.8296\n","====== Epoch: 56\n","====> Validation loss: 2.8088,  X1 loss: 2.8024   X2 loss: 2.8152\n","====== Epoch: 57\n","====> Validation loss: 2.8376,  X1 loss: 2.8324   X2 loss: 2.8427\n","====== Epoch: 58\n","====> Validation loss: 2.9031,  X1 loss: 2.8961   X2 loss: 2.9100\n","====== Epoch: 59\n","====> Validation loss: 2.8188,  X1 loss: 2.8085   X2 loss: 2.8291\n","====== Epoch: 60\n","====> Validation loss: 2.8388,  X1 loss: 2.8374   X2 loss: 2.8402\n","====== Epoch: 61\n","====> Validation loss: 2.8572,  X1 loss: 2.8427   X2 loss: 2.8717\n","====== Epoch: 62\n","====> Validation loss: 2.8441,  X1 loss: 2.8355   X2 loss: 2.8528\n","====== Epoch: 63\n","====> Validation loss: 2.8990,  X1 loss: 2.8827   X2 loss: 2.9153\n","====== Epoch: 64\n","====> Validation loss: 2.8138,  X1 loss: 2.8019   X2 loss: 2.8256\n","====== Epoch: 65\n","====> Validation loss: 2.8506,  X1 loss: 2.8386   X2 loss: 2.8625\n","====== Epoch: 66\n","====> Validation loss: 2.8636,  X1 loss: 2.8530   X2 loss: 2.8743\n","====== Epoch: 67\n","====> Validation loss: 2.8026,  X1 loss: 2.8007   X2 loss: 2.8044\n","====== Epoch: 68\n","====> Validation loss: 2.9045,  X1 loss: 2.8931   X2 loss: 2.9158\n","====== Epoch: 69\n","====> Validation loss: 2.8822,  X1 loss: 2.8651   X2 loss: 2.8994\n","====== Epoch: 70\n","====> Validation loss: 2.8494,  X1 loss: 2.8387   X2 loss: 2.8600\n","====== Epoch: 71\n","====> Validation loss: 2.7964,  X1 loss: 2.7874   X2 loss: 2.8053\n","====== Epoch: 72\n","====> Validation loss: 2.8805,  X1 loss: 2.8686   X2 loss: 2.8923\n","====== Epoch: 73\n","====> Validation loss: 2.8498,  X1 loss: 2.8372   X2 loss: 2.8624\n","====== Epoch: 74\n","====> Validation loss: 2.8218,  X1 loss: 2.8089   X2 loss: 2.8346\n","====== Epoch: 75\n","====> Validation loss: 2.8582,  X1 loss: 2.8311   X2 loss: 2.8853\n","====== Epoch: 76\n","====> Validation loss: 2.8988,  X1 loss: 2.8897   X2 loss: 2.9079\n","====== Epoch: 77\n","====> Validation loss: 2.8304,  X1 loss: 2.8242   X2 loss: 2.8366\n","====== Epoch: 78\n","====> Validation loss: 2.8556,  X1 loss: 2.8526   X2 loss: 2.8586\n","====== Epoch: 79\n","====> Validation loss: 2.8180,  X1 loss: 2.8034   X2 loss: 2.8326\n","====== Epoch: 80\n","====> Validation loss: 2.8419,  X1 loss: 2.8292   X2 loss: 2.8547\n","====== Epoch: 81\n","====> Validation loss: 2.9051,  X1 loss: 2.8930   X2 loss: 2.9173\n","====== Epoch: 82\n","====> Validation loss: 2.8599,  X1 loss: 2.8444   X2 loss: 2.8755\n","====== Epoch: 83\n","====> Validation loss: 2.8576,  X1 loss: 2.8443   X2 loss: 2.8708\n","====== Epoch: 84\n","====> Validation loss: 2.8426,  X1 loss: 2.8379   X2 loss: 2.8472\n","====== Epoch: 85\n","====> Validation loss: 2.8867,  X1 loss: 2.8747   X2 loss: 2.8986\n","====== Epoch: 86\n","====> Validation loss: 2.8928,  X1 loss: 2.8854   X2 loss: 2.9003\n","====== Epoch: 87\n","====> Validation loss: 2.8890,  X1 loss: 2.8789   X2 loss: 2.8992\n","====== Epoch: 88\n","====> Validation loss: 2.8427,  X1 loss: 2.8416   X2 loss: 2.8439\n","====== Epoch: 89\n","====> Validation loss: 2.8523,  X1 loss: 2.8380   X2 loss: 2.8667\n","====== Epoch: 90\n","====> Validation loss: 2.8787,  X1 loss: 2.8631   X2 loss: 2.8943\n","====== Epoch: 91\n","====> Validation loss: 2.8487,  X1 loss: 2.8441   X2 loss: 2.8533\n","====== Epoch: 92\n","====> Validation loss: 2.8545,  X1 loss: 2.8507   X2 loss: 2.8583\n","====== Epoch: 93\n","====> Validation loss: 2.8227,  X1 loss: 2.8134   X2 loss: 2.8319\n","====== Epoch: 94\n","====> Validation loss: 2.8880,  X1 loss: 2.8775   X2 loss: 2.8984\n","====== Epoch: 95\n","====> Validation loss: 2.8573,  X1 loss: 2.8469   X2 loss: 2.8676\n","====== Epoch: 96\n","====> Validation loss: 2.8361,  X1 loss: 2.8208   X2 loss: 2.8513\n","====== Epoch: 97\n","====> Validation loss: 2.8680,  X1 loss: 2.8439   X2 loss: 2.8922\n","====== Epoch: 98\n","====> Validation loss: 2.8589,  X1 loss: 2.8485   X2 loss: 2.8694\n","====== Epoch: 99\n","====> Validation loss: 2.8457,  X1 loss: 2.8361   X2 loss: 2.8553\n","====== Epoch: 100\n","====> Validation loss: 2.9185,  X1 loss: 2.9160   X2 loss: 2.9210\n","====== Epoch: 101\n","====> Validation loss: 2.8820,  X1 loss: 2.8640   X2 loss: 2.9000\n","====== Epoch: 102\n","====> Validation loss: 2.8089,  X1 loss: 2.7889   X2 loss: 2.8289\n","====== Epoch: 103\n","====> Validation loss: 2.8063,  X1 loss: 2.7986   X2 loss: 2.8140\n","====== Epoch: 104\n","====> Validation loss: 2.8503,  X1 loss: 2.8305   X2 loss: 2.8701\n","====== Epoch: 105\n","====> Validation loss: 2.8682,  X1 loss: 2.8570   X2 loss: 2.8795\n","====== Epoch: 106\n","====> Validation loss: 2.8397,  X1 loss: 2.8294   X2 loss: 2.8500\n","====== Epoch: 107\n","====> Validation loss: 2.8682,  X1 loss: 2.8581   X2 loss: 2.8784\n","====== Epoch: 108\n","====> Validation loss: 2.8335,  X1 loss: 2.8225   X2 loss: 2.8446\n","====== Epoch: 109\n","====> Validation loss: 2.8732,  X1 loss: 2.8557   X2 loss: 2.8908\n","====== Epoch: 110\n","====> Validation loss: 2.8900,  X1 loss: 2.8853   X2 loss: 2.8948\n","====== Epoch: 111\n","====> Validation loss: 2.8508,  X1 loss: 2.8465   X2 loss: 2.8552\n","====== Epoch: 112\n","====> Validation loss: 2.8061,  X1 loss: 2.7951   X2 loss: 2.8171\n","====== Epoch: 113\n","====> Validation loss: 2.8428,  X1 loss: 2.8336   X2 loss: 2.8521\n","====== Epoch: 114\n","====> Validation loss: 2.8155,  X1 loss: 2.7998   X2 loss: 2.8312\n","====== Epoch: 115\n","====> Validation loss: 2.8768,  X1 loss: 2.8723   X2 loss: 2.8813\n","====== Epoch: 116\n","====> Validation loss: 2.8319,  X1 loss: 2.8163   X2 loss: 2.8475\n","====== Epoch: 117\n","====> Validation loss: 2.7969,  X1 loss: 2.7896   X2 loss: 2.8041\n","====== Epoch: 118\n","====> Validation loss: 2.7897,  X1 loss: 2.7741   X2 loss: 2.8052\n","====== Epoch: 119\n","====> Validation loss: 2.8183,  X1 loss: 2.8133   X2 loss: 2.8234\n","====== Epoch: 120\n","====> Validation loss: 2.8170,  X1 loss: 2.8035   X2 loss: 2.8305\n","====== Epoch: 121\n","====> Validation loss: 2.7984,  X1 loss: 2.7893   X2 loss: 2.8075\n","====== Epoch: 122\n","====> Validation loss: 2.8279,  X1 loss: 2.8233   X2 loss: 2.8324\n","====== Epoch: 123\n","====> Validation loss: 2.8404,  X1 loss: 2.8289   X2 loss: 2.8520\n","====== Epoch: 124\n","====> Validation loss: 2.8701,  X1 loss: 2.8550   X2 loss: 2.8852\n","====== Epoch: 125\n","====> Validation loss: 2.8473,  X1 loss: 2.8359   X2 loss: 2.8586\n","====== Epoch: 126\n","====> Validation loss: 2.8202,  X1 loss: 2.8114   X2 loss: 2.8290\n","====== Epoch: 127\n","====> Validation loss: 2.8575,  X1 loss: 2.8444   X2 loss: 2.8707\n","====== Epoch: 128\n","====> Validation loss: 2.8207,  X1 loss: 2.8090   X2 loss: 2.8324\n","====== Epoch: 129\n","====> Validation loss: 2.8357,  X1 loss: 2.8203   X2 loss: 2.8510\n","====== Epoch: 130\n","====> Validation loss: 2.8240,  X1 loss: 2.8087   X2 loss: 2.8393\n","====== Epoch: 131\n","====> Validation loss: 2.7870,  X1 loss: 2.7784   X2 loss: 2.7957\n","====== Epoch: 132\n","====> Validation loss: 2.9029,  X1 loss: 2.8995   X2 loss: 2.9063\n","====== Epoch: 133\n","====> Validation loss: 2.8396,  X1 loss: 2.8345   X2 loss: 2.8447\n","====== Epoch: 134\n","====> Validation loss: 2.8359,  X1 loss: 2.8300   X2 loss: 2.8417\n","====== Epoch: 135\n","====> Validation loss: 2.8371,  X1 loss: 2.8226   X2 loss: 2.8517\n","====== Epoch: 136\n","====> Validation loss: 2.7946,  X1 loss: 2.7773   X2 loss: 2.8119\n","====== Epoch: 137\n","====> Validation loss: 2.8295,  X1 loss: 2.8195   X2 loss: 2.8394\n","====== Epoch: 138\n","====> Validation loss: 2.8140,  X1 loss: 2.8108   X2 loss: 2.8173\n","====== Epoch: 139\n","====> Validation loss: 2.8084,  X1 loss: 2.7958   X2 loss: 2.8211\n","====== Epoch: 140\n","====> Validation loss: 2.8445,  X1 loss: 2.8198   X2 loss: 2.8692\n","====== Epoch: 141\n","====> Validation loss: 2.8759,  X1 loss: 2.8587   X2 loss: 2.8931\n","====== Epoch: 142\n","====> Validation loss: 2.8361,  X1 loss: 2.8292   X2 loss: 2.8429\n","====== Epoch: 143\n","====> Validation loss: 2.8262,  X1 loss: 2.8084   X2 loss: 2.8440\n","====== Epoch: 144\n","====> Validation loss: 2.8583,  X1 loss: 2.8545   X2 loss: 2.8622\n","====== Epoch: 145\n","====> Validation loss: 2.8422,  X1 loss: 2.8354   X2 loss: 2.8489\n","====== Epoch: 146\n","====> Validation loss: 2.8559,  X1 loss: 2.8446   X2 loss: 2.8673\n","====== Epoch: 147\n","====> Validation loss: 2.8669,  X1 loss: 2.8502   X2 loss: 2.8836\n","====== Epoch: 148\n","====> Validation loss: 2.8661,  X1 loss: 2.8553   X2 loss: 2.8769\n","====== Epoch: 149\n","====> Validation loss: 2.7969,  X1 loss: 2.7836   X2 loss: 2.8102\n","====== Epoch: 150\n","====> Validation loss: 2.8362,  X1 loss: 2.8284   X2 loss: 2.8440\n","====== Epoch: 151\n","====> Validation loss: 2.7717,  X1 loss: 2.7668   X2 loss: 2.7766\n","====== Epoch: 152\n","====> Validation loss: 2.8482,  X1 loss: 2.8334   X2 loss: 2.8631\n","====== Epoch: 153\n","====> Validation loss: 2.8234,  X1 loss: 2.8104   X2 loss: 2.8364\n","====== Epoch: 154\n","====> Validation loss: 2.7953,  X1 loss: 2.7730   X2 loss: 2.8176\n","====== Epoch: 155\n","====> Validation loss: 2.8192,  X1 loss: 2.8089   X2 loss: 2.8296\n","====== Epoch: 156\n","====> Validation loss: 2.8014,  X1 loss: 2.7947   X2 loss: 2.8081\n","====== Epoch: 157\n","====> Validation loss: 2.8451,  X1 loss: 2.8342   X2 loss: 2.8560\n","====== Epoch: 158\n","====> Validation loss: 2.8262,  X1 loss: 2.8155   X2 loss: 2.8369\n","====== Epoch: 159\n","====> Validation loss: 2.8234,  X1 loss: 2.8150   X2 loss: 2.8318\n","====== Epoch: 160\n","====> Validation loss: 2.8743,  X1 loss: 2.8655   X2 loss: 2.8831\n","====== Epoch: 161\n","====> Validation loss: 2.8470,  X1 loss: 2.8274   X2 loss: 2.8666\n","====== Epoch: 162\n","====> Validation loss: 2.8529,  X1 loss: 2.8428   X2 loss: 2.8630\n","====== Epoch: 163\n","====> Validation loss: 2.8266,  X1 loss: 2.8066   X2 loss: 2.8465\n","====== Epoch: 164\n","====> Validation loss: 2.8431,  X1 loss: 2.8297   X2 loss: 2.8565\n","====== Epoch: 165\n","====> Validation loss: 2.8532,  X1 loss: 2.8438   X2 loss: 2.8627\n","====== Epoch: 166\n","====> Validation loss: 2.8539,  X1 loss: 2.8456   X2 loss: 2.8623\n","====== Epoch: 167\n","====> Validation loss: 2.8630,  X1 loss: 2.8447   X2 loss: 2.8814\n","====== Epoch: 168\n","====> Validation loss: 2.8519,  X1 loss: 2.8382   X2 loss: 2.8655\n","====== Epoch: 169\n","====> Validation loss: 2.8392,  X1 loss: 2.8266   X2 loss: 2.8519\n","====== Epoch: 170\n","====> Validation loss: 2.7756,  X1 loss: 2.7684   X2 loss: 2.7828\n","====== Epoch: 171\n","====> Validation loss: 2.8253,  X1 loss: 2.8138   X2 loss: 2.8369\n","====== Epoch: 172\n","====> Validation loss: 2.8616,  X1 loss: 2.8512   X2 loss: 2.8719\n","====== Epoch: 173\n","====> Validation loss: 2.8663,  X1 loss: 2.8531   X2 loss: 2.8796\n","====== Epoch: 174\n","====> Validation loss: 2.8476,  X1 loss: 2.8445   X2 loss: 2.8507\n","====== Epoch: 175\n","====> Validation loss: 2.7924,  X1 loss: 2.7881   X2 loss: 2.7967\n","====== Epoch: 176\n","====> Validation loss: 2.7827,  X1 loss: 2.7663   X2 loss: 2.7991\n","====== Epoch: 177\n","====> Validation loss: 2.8153,  X1 loss: 2.8032   X2 loss: 2.8273\n","====== Epoch: 178\n","====> Validation loss: 2.8360,  X1 loss: 2.8274   X2 loss: 2.8447\n","====== Epoch: 179\n","====> Validation loss: 2.8720,  X1 loss: 2.8662   X2 loss: 2.8779\n","====== Epoch: 180\n","====> Validation loss: 2.8539,  X1 loss: 2.8422   X2 loss: 2.8656\n","====== Epoch: 181\n","====> Validation loss: 2.8448,  X1 loss: 2.8235   X2 loss: 2.8661\n","====== Epoch: 182\n","====> Validation loss: 2.8378,  X1 loss: 2.8184   X2 loss: 2.8572\n","====== Epoch: 183\n","====> Validation loss: 2.8747,  X1 loss: 2.8569   X2 loss: 2.8925\n","====== Epoch: 184\n","====> Validation loss: 2.8859,  X1 loss: 2.8690   X2 loss: 2.9028\n","====== Epoch: 185\n","====> Validation loss: 2.8352,  X1 loss: 2.8316   X2 loss: 2.8388\n","====== Epoch: 186\n","====> Validation loss: 2.7930,  X1 loss: 2.7724   X2 loss: 2.8136\n","====== Epoch: 187\n","====> Validation loss: 2.7855,  X1 loss: 2.7818   X2 loss: 2.7892\n","====== Epoch: 188\n","====> Validation loss: 2.8226,  X1 loss: 2.8110   X2 loss: 2.8342\n","====== Epoch: 189\n","====> Validation loss: 2.8268,  X1 loss: 2.8080   X2 loss: 2.8456\n","====== Epoch: 190\n","====> Validation loss: 2.7936,  X1 loss: 2.7851   X2 loss: 2.8022\n","====== Epoch: 191\n","====> Validation loss: 2.8422,  X1 loss: 2.8211   X2 loss: 2.8633\n","====== Epoch: 192\n","====> Validation loss: 2.8504,  X1 loss: 2.8262   X2 loss: 2.8746\n","====== Epoch: 193\n","====> Validation loss: 2.8829,  X1 loss: 2.8627   X2 loss: 2.9031\n","====== Epoch: 194\n","====> Validation loss: 2.8501,  X1 loss: 2.8419   X2 loss: 2.8582\n","====== Epoch: 195\n","====> Validation loss: 2.8681,  X1 loss: 2.8538   X2 loss: 2.8825\n","====== Epoch: 196\n","====> Validation loss: 2.8392,  X1 loss: 2.8332   X2 loss: 2.8453\n","====== Epoch: 197\n","====> Validation loss: 2.8228,  X1 loss: 2.7989   X2 loss: 2.8468\n","====== Epoch: 198\n","====> Validation loss: 2.8190,  X1 loss: 2.8091   X2 loss: 2.8290\n","====== Epoch: 199\n","====> Validation loss: 2.8444,  X1 loss: 2.8346   X2 loss: 2.8541\n"]}],"source":["\n","lossi = []\n","udri = [] # update / data ratio \n","ud = []\n","\n","lr = 0.001\n","\n","for name, model in models_dict.items():\n","\n","    # Reset for the new model in the loop\n","    print(f\"+--------------New model: {name}----------------------+\")\n","    writer = SummaryWriter(log_dir=f\"runs/{name}_{time.strftime('%Y%m%d_%H%M%S')}\")\n","    model.to(device)\n","    optimizer = optim.NAdam(model.parameters(), lr=lr)\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.7)\n","    cnt = 0\n","    loss_batches = []\n","\n","\n","    for epoch in range(1, 200):\n","\n","        print(f\"====== Epoch: {epoch}\")\n","\n","        model.train()\n","        for ix_batch, (Xb_eeg, Xb_env) in enumerate(dataloader):\n","\n","            # send to device\n","            Xb_eeg = Xb_eeg.to(device)\n","            Xb_env = Xb_env.to(device)\n","\n","            # Zero out gradients\n","            optimizer.zero_grad()\n","\n","            # forward pass\n","            eeg_features, env_features, logit_scale = model(Xb_eeg, Xb_env) \n","\n","\n","            # normalize features\n","            eeg_features_n = eeg_features / eeg_features.norm(dim=1, keepdim=True)\n","            env_features_n = env_features / env_features.norm(dim=1, keepdim=True)\n","\n","            # logits\n","            logits_per_eeg = logit_scale * eeg_features_n @ env_features_n.t()\n","            logits_per_env = logits_per_eeg.t()\n","\n","            #loss function\n","            labels = torch.arange(batch_size).to(device)\n","            loss_eeg = F.cross_entropy(logits_per_eeg, labels)\n","            loss_env = F.cross_entropy(logits_per_env, labels)\n","            loss   = (loss_eeg + loss_env)/2\n","\n","            # backward pass\n","            loss.backward()\n","            optimizer.step()\n","\n","            loss_batches.append(loss.item())\n","            cnt += 1\n","\n","            with torch.no_grad():\n","                #ud = {f\"p{ix}\":(lr*p.grad.std() / p.data.std()).log10().item() for ix, p in enumerate(model.parameters()) if p.ndim==4 }\n","                #writer.add_scalars('UpdateOData/ud', ud, cnt)\n","                writer.add_scalar('Loss/train_batch', loss.item(), cnt)\n","\n","            # normalize weights\n","            with torch.no_grad():\n","                normalize_weights_eegnet(model.eeg_encoder)\n","            \n","            #break   \n","\n","        loss_epoch = loss_batches[-(ix_batch + 1):]  # mean loss across batches\n","        loss_epoch = sum(loss_epoch) / len(loss_epoch)\n","        writer.add_scalar('Loss/train_epoch', loss_epoch, epoch)\n","        #for pname, p in model.named_parameters():\n","        #writer.add_histogram(f'Params/{pname}', p, epoch)\n","        #writer.add_histogram(f'Grads/{pname}', p.grad, epoch)\n","\n","        loss_val, *_ = eval_model_cl(dl_val, model, device=device)\n","        writer.add_scalar('Loss/val_epoch', loss_val, epoch)\n","\n","        \n","\n","        model.train()\n","\n","        # Update learning rate based on epoch\n","        scheduler.step()\n","            \n","    #break   \n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"13Poz5tFnEFXpegMbhqAinRdIfSvPnPge","timestamp":1677524195292}],"collapsed_sections":["VhCK252zNjUG"]},"gpuClass":"premium","kernelspec":{"display_name":"mne","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"8e19e54895c02f0e9343d0fbd6cee45458aaf6f05de9ab3004d10bba5525a5d0"}}},"nbformat":4,"nbformat_minor":0}