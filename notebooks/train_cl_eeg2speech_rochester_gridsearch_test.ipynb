{"cells":[{"cell_type":"markdown","metadata":{"id":"aXEXbz7ENjUM"},"source":["## Main code"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677770794962,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"EOmC9QbE-kZz"},"outputs":[],"source":["#%reset"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5065,"status":"ok","timestamp":1677770800021,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"gGggzCoKZQeu","outputId":"520b7a55-a9ff-4ea6-9339-951589cd19bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["import os, sys, glob\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import numpy as np\n","\n","import mne\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import time\n","\n","from torchsummary import summary\n","from torch.utils.tensorboard import SummaryWriter\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","from tools.train import eval_model_cl\n","from tools.data import unfold_raw, rm_repeated_annotations\n","from tools.load_data import load_data\n"]},{"cell_type":"markdown","metadata":{"id":"q4sGJAdFZQez"},"source":["## Read Data"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1677770800022,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"KdQFfHcJZQe0","outputId":"277bf1f6-a0d2-4ab0-d473-164315b2b943"},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------------------------------\n","window_size: 640  stride_size_test: 640\n","data_path: ../outputs/rochester_data/natural_speech\n"]}],"source":["subj_ids = [1] #list(range(1, 20))\n","fs = 128\n","window_size = int(5 * fs)\n","stride_size_train, stride_size_val, stride_size_test = int(2.5 * fs), int(5 * fs), int(5 * fs)\n","n_channs = 129 # 128 for eeg, 1 for env\n","batch_size = int(32)\n","print('-------------------------------------')\n","print(f'window_size: {window_size}  stride_size_test: {stride_size_test}')\n","\n","dataset_name = ['rochester_data', 'natural_speech']\n","outputs_path = f'../outputs/'\n","data_path = os.path.join(outputs_path, dataset_name[0], dataset_name[1])\n","after_ica_path = os.path.join(data_path, 'after_ica_raw')\n","print(f'data_path: {data_path}')"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_1_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 48  Num of removed annots: 19  Num of retained annots:  29\n","-------------------------------------\n","N train: 26  N val: 1  N test: 1\n","Shape Trian: torch.Size([1204, 1, 129, 640])  Shape Val: torch.Size([36, 1, 129, 640])  Shape Test: torch.Size([36, 1, 129, 640])\n","-------------------------------------\n","Shape EEG Train: torch.Size([1204, 1, 128, 640])  Val: torch.Size([36, 1, 128, 640])  Test: torch.Size([36, 1, 128, 640])\n","Mean: 9.050915399100301e-12  Std: 5.065590812591836e-06\n","Shape Env Train: torch.Size([1204, 1, 1, 640])  Val: torch.Size([36, 1, 1, 640])  Test: torch.Size([36, 1, 1, 640])\n","Mean Env: 2.364877700805664  Std Env: 2.5979256629943848\n"]}],"source":["\n","X = load_data(subj_ids, after_ica_path, window_size, stride_size_train, stride_size_val, stride_size_test, n_channs)"]},{"cell_type":"markdown","metadata":{"id":"tesRTfOdZQe2"},"source":["### Pytorch dataloader"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1677771078458,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"HviGOmH1ZQe2"},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, eeg, env):\n","        self.eeg = eeg\n","        self.env = env\n","    \n","    def __getitem__(self, index):\n","        return self.eeg[index], self.env[index]\n","    \n","    def __len__(self):\n","        return len(self.eeg)\n","    \n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["dataset_train = MyDataset(X['eegs_train'], X['envs_train'])\n","dl_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","dl_val = DataLoader(MyDataset(X[\"eegs_val\"], X[\"envs_val\"]), batch_size=batch_size, shuffle=True, drop_last=True)"]},{"cell_type":"markdown","metadata":{"id":"XMjI2NeFZQe3"},"source":["## Model"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 320])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 8, 128, 640]             520\n","       BatchNorm2d-2          [-1, 8, 128, 640]              16\n","            Conv2d-3           [-1, 16, 1, 640]           2,048\n","       BatchNorm2d-4           [-1, 16, 1, 640]              32\n","               ELU-5           [-1, 16, 1, 640]               0\n","         AvgPool2d-6           [-1, 16, 1, 160]               0\n","           Dropout-7           [-1, 16, 1, 160]               0\n","            Conv2d-8           [-1, 16, 1, 160]             256\n","            Conv2d-9           [-1, 16, 1, 160]             256\n","      BatchNorm2d-10           [-1, 16, 1, 160]              32\n","              ELU-11           [-1, 16, 1, 160]               0\n","        AvgPool2d-12            [-1, 16, 1, 20]               0\n","          Dropout-13            [-1, 16, 1, 20]               0\n","          Flatten-14                  [-1, 320]               0\n","================================================================\n","Total params: 3,160\n","Trainable params: 3,160\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.31\n","Forward/backward pass size (MB): 10.36\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 10.68\n","----------------------------------------------------------------\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 4, 1, 640]             260\n","       BatchNorm2d-2            [-1, 4, 1, 640]               8\n","               ELU-3            [-1, 4, 1, 640]               0\n","         AvgPool2d-4            [-1, 4, 1, 320]               0\n","           Dropout-5            [-1, 4, 1, 320]               0\n","            Conv2d-6            [-1, 4, 1, 320]             512\n","       BatchNorm2d-7            [-1, 4, 1, 320]               8\n","               ELU-8            [-1, 4, 1, 320]               0\n","         AvgPool2d-9            [-1, 4, 1, 160]               0\n","          Dropout-10            [-1, 4, 1, 160]               0\n","           Conv2d-11           [-1, 16, 1, 160]           1,024\n","      BatchNorm2d-12           [-1, 16, 1, 160]              32\n","              ELU-13           [-1, 16, 1, 160]               0\n","        AvgPool2d-14            [-1, 16, 1, 20]               0\n","          Dropout-15            [-1, 16, 1, 20]               0\n","          Flatten-16                  [-1, 320]               0\n","================================================================\n","Total params: 1,844\n","Trainable params: 1,844\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.18\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.19\n","----------------------------------------------------------------\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 8, 128, 640]             520\n","       BatchNorm2d-2          [-1, 8, 128, 640]              16\n","            Conv2d-3           [-1, 16, 1, 640]           2,048\n","       BatchNorm2d-4           [-1, 16, 1, 640]              32\n","               ELU-5           [-1, 16, 1, 640]               0\n","         AvgPool2d-6           [-1, 16, 1, 160]               0\n","           Dropout-7           [-1, 16, 1, 160]               0\n","            Conv2d-8           [-1, 16, 1, 160]             256\n","            Conv2d-9           [-1, 16, 1, 160]             256\n","      BatchNorm2d-10           [-1, 16, 1, 160]              32\n","              ELU-11           [-1, 16, 1, 160]               0\n","        AvgPool2d-12            [-1, 16, 1, 20]               0\n","          Dropout-13            [-1, 16, 1, 20]               0\n","          Flatten-14                  [-1, 320]               0\n","       EEGEncoder-15                  [-1, 320]               0\n","           Conv2d-16            [-1, 4, 1, 640]             260\n","      BatchNorm2d-17            [-1, 4, 1, 640]               8\n","              ELU-18            [-1, 4, 1, 640]               0\n","        AvgPool2d-19            [-1, 4, 1, 320]               0\n","          Dropout-20            [-1, 4, 1, 320]               0\n","           Conv2d-21            [-1, 4, 1, 320]             512\n","      BatchNorm2d-22            [-1, 4, 1, 320]               8\n","              ELU-23            [-1, 4, 1, 320]               0\n","        AvgPool2d-24            [-1, 4, 1, 160]               0\n","          Dropout-25            [-1, 4, 1, 160]               0\n","           Conv2d-26           [-1, 16, 1, 160]           1,024\n","      BatchNorm2d-27           [-1, 16, 1, 160]              32\n","              ELU-28           [-1, 16, 1, 160]               0\n","        AvgPool2d-29            [-1, 16, 1, 20]               0\n","          Dropout-30            [-1, 16, 1, 20]               0\n","          Flatten-31                  [-1, 320]               0\n","  EnvelopeEncoder-32                  [-1, 320]               0\n","================================================================\n","Total params: 5,004\n","Trainable params: 5,004\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 200.00\n","Forward/backward pass size (MB): 10.55\n","Params size (MB): 0.02\n","Estimated Total Size (MB): 210.57\n","----------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/Users/keyvan.mahjoory/opt/anaconda3/envs/mne/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525699189/work/aten/src/ATen/native/Convolution.cpp:896.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]}],"source":["import torch\n","from models.eeg_encoder import EEGEncoder\n","from models.envelope_encoder import EnvelopeEncoder\n","from models.contrastive_eeg_speech import CLEE\n","eeg_encoder = EEGEncoder()\n","env_encoder = EnvelopeEncoder()\n","model = CLEE(eeg_encoder, env_encoder)\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(eeg_encoder(X['eegs_train'][:32, :, :, :]).shape)\n","\n","summary(eeg_encoder, (1, 128, 640))\n","summary(env_encoder, (1, 1, 640))\n","summary(model, [(1, 128, 640), (1, 1, 640)])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":8511458,"status":"ok","timestamp":1677781695965,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"d4iJiosNZQe7","outputId":"7cee43df-ead8-41a4-e403-46d0eee82c01"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------New model: SIMPLE----------------------+\n","====== Epoch: 1\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","====> Validation loss: 3.3886,  X1 loss: 3.3917   X2 loss: 3.3854\n","====== Epoch: 2\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","====> Validation loss: 3.2480,  X1 loss: 3.2593   X2 loss: 3.2367\n","====== Epoch: 3\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n","_____\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m loss   \u001b[39m=\u001b[39m (loss_eeg \u001b[39m+\u001b[39m loss_env)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[39m# backward pass\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     54\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     56\u001b[0m loss_batches\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n","File \u001b[0;32m~/opt/anaconda3/envs/mne/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n","File \u001b[0;32m~/opt/anaconda3/envs/mne/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["models_dict = {'SIMPLE': model}\n","lossi = []\n","udri = [] # update / data ratio \n","ud = []\n","\n","lr = 0.001\n","\n","for name, model in models_dict.items():\n","\n","    # Reset for the new model in the loop\n","    print(f\"+--------------New model: {name}----------------------+\")\n","    writer = SummaryWriter(log_dir=f\"runs/{name}_{time.strftime('%Y%m%d_%H%M%S')}\")\n","    model.to(device)\n","    optimizer = optim.NAdam(model.parameters(), lr=lr)\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.7)\n","    cnt = 0\n","    loss_batches = []\n","\n","\n","    for epoch in range(1, 50):\n","\n","        print(f\"====== Epoch: {epoch}\")\n","\n","        model.train()\n","        for ix_batch, (Xb_eeg, Xb_env) in enumerate(dl_train):\n","\n","            # send to device\n","            Xb_eeg = Xb_eeg.to(device)\n","            Xb_env = Xb_env.to(device)\n","\n","            # Zero out gradients\n","            optimizer.zero_grad()\n","\n","            # forward pass\n","            eeg_features, env_features, logit_scale = model(Xb_eeg, Xb_env) \n","\n","\n","            # normalize features\n","            eeg_features_n = eeg_features / eeg_features.norm(dim=1, keepdim=True)\n","            env_features_n = env_features / env_features.norm(dim=1, keepdim=True)\n","\n","            # logits\n","            logits_per_eeg = logit_scale * eeg_features_n @ env_features_n.t()\n","            logits_per_env = logits_per_eeg.t()\n","\n","            #loss function\n","            labels = torch.arange(batch_size).to(device)\n","            loss_eeg = F.cross_entropy(logits_per_eeg, labels)\n","            loss_env = F.cross_entropy(logits_per_env, labels)\n","            loss   = (loss_eeg + loss_env)/2\n","\n","            # backward pass\n","            loss.backward()\n","            optimizer.step()\n","\n","            loss_batches.append(loss.item())\n","            cnt += 1\n","\n","            with torch.no_grad():\n","                #ud = {f\"p{ix}\":(lr*p.grad.std() / p.data.std()).log10().item() for ix, p in enumerate(model.parameters()) if p.ndim==4 }\n","                #writer.add_scalars('UpdateOData/ud', ud, cnt)\n","                writer.add_scalar('Loss/train_batch', loss.item(), cnt)\n","\n","            # normalize weights\n","            with torch.no_grad():\n","                model.eeg_encoder.normalize_weights()\n","            \n","            #break   \n","\n","        loss_epoch = loss_batches[-(ix_batch + 1):]  # mean loss across batches\n","        loss_epoch = sum(loss_epoch) / len(loss_epoch)\n","        writer.add_scalar('Loss/train_epoch', loss_epoch, epoch)\n","        #for pname, p in model.named_parameters():\n","        #writer.add_histogram(f'Params/{pname}', p, epoch)\n","        #writer.add_histogram(f'Grads/{pname}', p.grad, epoch)\n","\n","        loss_val, *_ = eval_model_cl(dl_val, model, device=device)\n","        writer.add_scalar('Loss/val_epoch', loss_val, epoch)\n","\n","        \n","\n","        model.train()\n","\n","        # Update learning rate based on epoch\n","        scheduler.step()\n","            \n","    #break   \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["VhCK252zNjUG"],"machine_shape":"hm","provenance":[{"file_id":"13Poz5tFnEFXpegMbhqAinRdIfSvPnPge","timestamp":1677524195292}]},"gpuClass":"premium","kernelspec":{"display_name":"Python (mne)","language":"python","name":"mne"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"8e19e54895c02f0e9343d0fbd6cee45458aaf6f05de9ab3004d10bba5525a5d0"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"736632aa328443f7a1e9a85d67da40da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0bb2a650ba0447d832f6a1bf47dd4b4":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_736632aa328443f7a1e9a85d67da40da","msg_id":"","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">     <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">7.6/7.6 MB</span> <span style=\"color: #800000; text-decoration-color: #800000\">64.9 MB/s</span> eta <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span>\n</pre>\n","text/plain":"     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}}}}},"nbformat":4,"nbformat_minor":0}
